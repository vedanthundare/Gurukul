{
  "subject": "aptitude",
  "topic": "ratio and proportion",
  "wikipedia": {
    "title": "Glossary of engineering: M–Z",
    "summary": "This glossary of engineering terms is a list of definitions about the major concepts of engineering. Please see the bottom of the page for glossaries of specific fields of engineering.\n\n",
    "content": "This glossary of engineering terms is a list of definitions about the major concepts of engineering. Please see the bottom of the page for glossaries of specific fields of engineering.\n\n\n== M ==\n\nMacaulay's method(The double integration method) is a technique used in structural analysis to determine the deflection of Euler-Bernoulli beams. Use of Macaulay's technique is very convenient for cases of discontinuous and/or discrete loading. Typically partial uniformly distributed loads (u.d.l.) and uniformly varying loads (u.v.l.) over the span and a number of concentrated loads are conveniently handled using this technique.\nMach numberThe ratio of the speed of an object to the speed of sound. \nMachineA machine (or mechanical device) is a mechanical structure that uses power to apply forces and control movement to perform an intended action. Machines can be driven by animals and people, by natural forces such as wind and water, and by chemical, thermal, or electrical power, and include a system of mechanisms that shape the actuator input to achieve a specific application of output forces and movement. They can also include computers and sensors that monitor performance and plan movement, often called mechanical systems.\nMachine codeIn computer programming, machine code, consisting of machine language instructions, is a low-level programming language used to directly control a computer's central processing unit (CPU). Each instruction causes the CPU to perform a very specific task, such as a load, a store, a jump, or an arithmetic logic unit (ALU) operation on one or more units of data in the CPU's registers or memory.\nMachine elementor hardware, refers to an elementary component of a machine.  These elements consist of three basic types:\nstructural components such as frame members, bearings, axles, splines, fasteners, seals, and lubricants,\nmechanisms that control movement in various ways such as gear trains, belt or chain drives, linkages, cam and follower systems, including brakes and clutches, and\ncontrol components such as buttons, switches, indicators, sensors, actuators and computer controllers.\n\nWhile generally not considered to be a machine element, the shape, texture and color of covers are an important part of a machine that provide a styling and operational interface between the mechanical components of a machine and its users.\n\nMachine elements are basic mechanical parts and features used as the building blocks of most machines. Most are standardized to common sizes, but customs are also common for specialized applications.\nMachine learning(ML), is the study of computer algorithms that improve automatically through experience and by the use of data. It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.\nMaclaurin seriesIn mathematics, the Taylor series of a function is an infinite sum of terms that are expressed in terms of the function's derivatives at a single point. For most common functions, the function and the sum of its Taylor series are equal near this point. Taylor's series are named after Brook Taylor,  who introduced them in 1715.  If zero is the point where the derivatives are considered, a Taylor series is also called a Maclaurin series, after Colin Maclaurin, who made extensive use of this special case of Taylor series in the 18th century.\nMagnetic fieldA magnetic field is a vector field that describes the magnetic influence on moving electric charges, electric currents,: ch1  and magnetic materials. A moving charge in a magnetic field experiences a force perpendicular to its own velocity and to the magnetic field.: ch13   A permanent magnet's magnetic field pulls on ferromagnetic materials such as iron, and attracts or repels other magnets.  In addition, a magnetic field that varies with location will exert a force on a range of non-magnetic materials by affecting the motion of their outer atomic electrons. Magnetic fields surround magnetized materials, and are created by electric currents such as those used in electromagnets, and by electric fields varying in time.  Since both strength and direction of a magnetic field may vary with location, they are described as a map assigning a vector to each point of space or, more precisely—because of the way the magnetic field transforms under mirror reflection—as a field of pseudovectors.\n\nIn electromagnetics, the term \"magnetic field\" is used for two distinct but closely related vector fields denoted by the symbols B and H. In the International System of Units, H, magnetic field strength, is measured in the SI base units of ampere per meter (A/m). B, magnetic flux density, is measured in tesla (in SI base units: kilogram per second2 per ampere), which is equivalent to newton per meter per ampere. H and B differ in how they account for magnetization. In vacuum, the two fields are related through the vacuum permeability, \n  \n    \n      \n        \n          B\n        \n        \n          /\n        \n        \n          μ\n          \n            0\n          \n        \n        =\n        \n          H\n        \n      \n    \n    {\\displaystyle \\mathbf {B} /\\mu _{0}=\\mathbf {H} }\n  \n; but in a magnetized material, the terms differ by the material's magnetization at each point.\nMagnetismis a class of physical attributes that are mediated by magnetic fields. Electric currents and the magnetic moments of elementary particles give rise to a magnetic field, which acts on other currents and magnetic moments. Magnetism is one aspect of the combined phenomenon of electromagnetism. The most familiar effects occur in ferromagnetic materials, which are strongly attracted by magnetic fields and can be magnetized to become permanent magnets, producing magnetic fields themselves.  Demagnetizing a magnet is also possible.  Only a few substances are ferromagnetic; the most common ones are iron, cobalt and nickel and their alloys. The rare-earth metals neodymium and samarium are less common examples. The prefix ferro- refers to iron, because permanent magnetism was first observed in lodestone, a form of natural iron ore called magnetite, Fe3O4.\nManufacturing engineeringis a branch of professional engineering that shares many common concepts and ideas with other fields of engineering such as mechanical, chemical, electrical, and industrial engineering. \nManufacturing engineering requires the ability to plan the practices of manufacturing; to research and to develop tools, processes, machines and equipment; and to integrate the facilities and systems for producing quality products with the optimum expenditure of capital.\n\nThe manufacturing or production engineer's primary focus is to turn raw material into an updated or new product in the most effective, efficient & economic way possible.\nMass balanceA mass balance, also called a material balance, is an application of conservation of mass to the analysis of physical systems. By accounting for material entering and leaving a system, mass flows can be identified which might have been unknown, or difficult to measure without this technique.  The exact conservation law used in the analysis of the system depends on the context of the problem, but all revolve around mass conservation, i.e., that matter cannot disappear or be created spontaneously.: 59–62 \nMass densityThe density (more precisely, the volumetric mass density; also known as specific mass), of a substance is its mass per unit volume. The symbol most often used for density is ρ (the lower case Greek letter rho), although the Latin letter D can also be used. Mathematically, density is defined as mass divided by volume:\n\n  \n    \n      \n        ρ\n        =\n        \n          \n            m\n            V\n          \n        \n      \n    \n    {\\displaystyle \\rho ={\\frac {m}{V}}}\n  \n\nwhere ρ is the density, m is the mass, and V is the volume. In some cases (for instance, in the United States oil and gas industry), density is loosely defined as its weight per unit volume, although this is scientifically inaccurate – this quantity is more specifically called specific weight.\nMass moment of inertiaThe moment of inertia, otherwise known as the mass moment of inertia, angular mass, second moment of mass, or most accurately, rotational inertia, of a rigid body is a quantity that determines the torque needed for a desired angular acceleration about a rotational axis, akin to how mass determines the force needed for a desired acceleration. It depends on the body's mass distribution and the axis chosen, with larger moments requiring more torque to change the body's rate of rotation.\nMass numberThe mass number (symbol A, from the German word Atomgewicht [atomic weight]), also called  atomic mass number or nucleon number, is the total number of protons and neutrons (together known as nucleons) in an atomic nucleus. It is approximately equal to the atomic (also known as isotopic) mass of the atom expressed in daltons. Since protons and neutrons are both baryons, the mass number A is identical with the baryon number B of the nucleus (and also of the whole atom or ion). The mass number is different for each different isotope of a chemical element. Hence, the difference between the mass number and the atomic number Z gives the number of neutrons (N) in a given nucleus: N = A − Z.\n\nThe mass number is written either after the element name or as a superscript to the left of an element's symbol. For example, the most common isotope of carbon is carbon-12, or 12C, which has 6 protons and 6 neutrons. The full isotope symbol would also have the atomic number (Z) as a subscript to the left of the element symbol directly below the mass number: 126C.\nMass spectrometry(MS), is an analytical technique that is used to measure the mass-to-charge ratio of  ions. The results are typically presented as a mass spectrum, a plot of intensity as a function of the mass-to-charge ratio. Mass spectrometry is used in many different fields and is applied to pure samples as well as complex mixtures.\nMaterial failure theoryis an interdisciplinary field of materials science and solid mechanics which attempts to predict the conditions under which solid materials fail under the action of external loads. The failure of a material is usually classified into brittle failure (fracture) or ductile failure (yield). Depending on the conditions (such as temperature, state of stress, loading rate) most materials can fail in a brittle or ductile manner or both. However, for most practical situations, a material may be classified as either brittle or ductile.\n\nIn mathematical terms, failure theory is expressed in the form of various failure criteria which are valid for specific materials.  Failure criteria are functions in stress or strain space which separate \"failed\" states from \"unfailed\" states.  A precise physical definition of a \"failed\" state is not easily quantified and several working definitions are in use in the engineering community.  Quite often, phenomenological failure criteria of the same form are used to predict brittle failure and ductile yields.\nMaterial propertiesA material's property is an intensive property of some material, i.e., a physical property that does not depend on the amount of the material. These quantitative properties may be used as a metric by which the benefits of one material versus another can be compared, thereby aiding in materials selection.\nMaterials scienceThe interdisciplinary field of materials science, also commonly termed materials science and engineering, covers the design and discovery of new materials, particularly solids. The intellectual origins of materials science stem from the Enlightenment, when researchers began to use analytical thinking from chemistry, physics, and engineering to understand ancient, phenomenological observations in metallurgy and mineralogy. Materials science still incorporates elements of physics, chemistry, and engineering. As such, the field was long considered by academic institutions as a sub-field of these related fields. Beginning in the 1940s, materials science began to be more widely recognized as a specific and distinct field of science and engineering, and major technical universities around the world created dedicated schools for its study.\n\nMaterials scientists emphasize understanding, how the history of a material (processing) influences its structure, and thus the material's properties and performance. The understanding of processing-structure-properties relationships is called the materials paradigm. This paradigm is used to advance understanding in a variety of research areas, including nanotechnology, biomaterials, and metallurgy.\n\nMaterials science is also an important part of forensic engineering and failure analysis –  investigating materials, products, structures or components, which fail or do not function as intended, causing personal injury or damage to property. Such investigations are key to understanding, for example, the causes of various aviation accidents and incidents.\nMathematical optimizationMathematical optimization (alternatively spelled optimisation) or mathematical programming is the selection of a best element, with regard to some criterion, from some set of available alternatives. Optimization problems of sorts arise in all quantitative disciplines from computer science and engineering to operations research and economics, and the development of solution methods has been of interest in mathematics for centuries.\n\nIn the simplest case, an optimization problem consists of maximizing or minimizing a real function by systematically choosing input values from within an allowed set and computing the value of the function. The generalization of optimization theory and techniques to other formulations constitutes a large area of applied mathematics. More generally, optimization includes finding \"best available\" values of some objective function given a defined domain (or input), including a variety of different types of objective functions and different types of domains.\nMathematical physicsrefers to the development of mathematical methods for application to problems in physics. The Journal of Mathematical Physics defines the field as \"the application of mathematics to problems in physics and the development of mathematical methods suitable for such applications and for the formulation of physical theories\".\nMathematicsincludes the study of such topics as quantity (number theory), structure (algebra), space (geometry), and change (analysis). It has no generally accepted definition.\n\nMathematicians seek and use patterns to formulate new conjectures; they resolve the truth or falsity of such by mathematical proof. When mathematical structures are good models of real phenomena, mathematical reasoning can be used to provide insight or predictions about nature. Through the use of abstraction and logic, mathematics developed from counting, calculation, measurement, and the systematic study of the shapes and motions of physical objects. Practical mathematics has been a human activity from as far back as written records exist. The research required to solve mathematical problems can take years or even centuries of sustained inquiry.\nMatrixIn mathematics, a matrix (plural matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object. For example, \n\n  \n    \n      \n        \n          \n            [\n            \n              \n                \n                  1\n                \n                \n                  9\n                \n                \n                  −\n                  13\n                \n              \n              \n                \n                  20\n                \n                \n                  5\n                \n                \n                  −\n                  6\n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle {\\begin{bmatrix}1&9&-13\\\\20&5&-6\\end{bmatrix}}}\n  \n\nis a matrix with two rows and three columns; one say often a \"two by three matrix\", a \"2×3-matrix\", or a matrix of dimension 2×3.\n\nWithout further specifications, matrices represent linear maps, and allow explicit computations in linear algebra. Therefore, the study of matrices is a large part of linear algebra, and most properties and operations of abstract linear algebra can be expressed in terms of matrices. For example, matrix multiplication represents composition of linear maps.\n\nNot all matrices are related to linear algebra. This is in particular the case, in graph theory, of incidence matrices and adjacency matrices.\nMatterIn classical physics and general chemistry, matter is any substance that has mass and takes up space by having volume. All everyday objects that can be touched are ultimately composed of atoms, which are made up of interacting subatomic particles, and in everyday as well as scientific usage, \"matter\" generally includes atoms and anything made up of them, and any particles (or combination of particles) that act as if they have both rest mass and volume. However it does not include massless particles such as photons, or other energy phenomena or waves such as light.: 21  Matter exists in various states (also known as phases). These include classical everyday phases such as solid, liquid, and gas – for example water exists as ice, liquid water, and gaseous steam – but other states are possible, including plasma, Bose–Einstein condensates, fermionic condensates, and quark–gluon plasma.\nMaximum-distortion energy theory.\nMaximum-normal-stress theory.\nMaximum shear stress.\nMaxwell's equationsare a set of coupled partial differential equations that, together with the Lorentz force law, form the foundation of classical electromagnetism, classical optics, and electric circuits. \nThe equations provide a mathematical model for electric, optical, and radio technologies, such as power generation, electric motors, wireless communication, lenses, radar etc. They describe how electric and magnetic fields are generated by charges, currents, and changes of the fields. The equations are named after the physicist and mathematician James Clerk Maxwell, who, in 1861 and 1862, published an early form of the equations that included the Lorentz force law. Maxwell first used the equations to propose that light is an electromagnetic phenomenon.\n\nAn important consequence of Maxwell's equations is that they demonstrate how fluctuating electric and magnetic fields propagate at a constant speed (c) in vacuum. Known as electromagnetic radiation, these waves may occur at various wavelengths to produce a spectrum of light from radio waves to gamma rays. \nMeanThere are several kinds of mean in mathematics, especially in statistics:\n\nFor a data set, the arithmetic mean, also known as average or arithmetic average, is a central value of a finite set of numbers: specifically, the sum of the values divided by the number of values. The arithmetic mean of a set of numbers x1, x2, ..., xn is typically denoted by \n  \n    \n      \n        \n          \n            \n              x\n              ¯\n            \n          \n        \n      \n    \n    {\\displaystyle {\\bar {x}}}\n  \n. If the data set were based on a series of observations obtained by sampling from a statistical population, the arithmetic mean is the sample mean (denoted \n  \n    \n      \n        \n          \n            \n              x\n              ¯\n            \n          \n        \n      \n    \n    {\\displaystyle {\\bar {x}}}\n  \n) to distinguish it from the mean, or expected value, of the underlying distribution, the population mean (denoted \n  \n    \n      \n        μ\n      \n    \n    {\\displaystyle \\mu }\n  \n or \n  \n    \n      \n        \n          μ\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle \\mu _{x}}\n  \n).\n\nIn probability and statistics, the population mean, or expected value, is a measure of the central tendency either of a probability distribution or of a random variable characterized by that distribution. In a discrete probability distribution of a random variable X, the mean is equal to the sum over every possible value weighted by the probability of that value; that is, it is computed by taking the product of each possible value x of X and its probability p(x), and then adding all these products together, giving \n  \n    \n      \n        μ\n        =\n        ∑\n        x\n        p\n        (\n        x\n        )\n        .\n        .\n        .\n        .\n      \n    \n    {\\displaystyle \\mu =\\sum xp(x)....}\n  \n. An analogous formula applies to the case of a continuous probability distribution. Not every probability distribution has a defined mean (see the Cauchy distribution for an example). Moreover, the mean can be infinite for some distributions.\n\nFor a finite population, the population mean of a property is equal to the arithmetic mean of the given property, while considering every member of the population. For example, the population mean height is equal to the sum of the heights of every individual—divided by the total number of individuals. The sample mean may differ from the population mean, especially for small samples. The law of large numbers states that the larger the size of the sample, the more likely it is that the sample mean will be close to the population mean.\n\nOutside probability and statistics, a wide range of other notions of mean are often used in geometry and mathematical analysis.\nMeasure of central tendencyIn statistics, a central tendency (or measure of central tendency) is a central or typical value for a probability distribution. It may also be called a center or location of the distribution. Colloquially, measures of central tendency are often called averages. The term central tendency dates from the late 1920s.\n\nThe most common measures of central tendency are the arithmetic mean, the median, and the mode.  A middle tendency can be calculated for either a finite set of values or for a theoretical distribution, such as the normal distribution. Occasionally authors use central tendency to denote \"the tendency of quantitative data to cluster around some central value.\"\n\nThe central tendency of a distribution is typically contrasted with its dispersion or variability; dispersion and central tendency are the often characterized properties of distributions. Analysis may judge whether data has a strong or a weak central tendency based on its dispersion.\nMechanical advantageis a measure of the force amplification achieved by using a tool, mechanical device or machine system. The device trades off input forces against movement to obtain a desired amplification in the output force.  The model for this is the law of the lever.  Machine components designed to manage forces and movement in this way are called mechanisms.  \nAn ideal mechanism transmits power without adding to or subtracting from it.  This means the ideal mechanism does not include a power source, is frictionless, and is constructed from rigid bodies that do not deflect or wear.  The performance of a real system relative to this ideal is expressed in terms of efficiency factors that take into account departures from the ideal.\nMechanical engineeringis an engineering branch that combines engineering physics and mathematics principles with materials science to design, analyze, manufacture, and maintain mechanical systems. It is one of the oldest and broadest of the engineering branches.\nMechanical filteris a signal processing filter usually used in place of an electronic filter at radio frequencies.  Its purpose is the same as that of a normal electronic filter: to pass a range of signal frequencies, but to block others.  The filter acts on mechanical vibrations which are the analogue of the electrical signal.  At the input and output of the filter, transducers convert the electrical signal into, and then back from, these mechanical vibrations.\nMechanical waveis a wave that is an oscillation of matter, and therefore transfers energy through a medium. While waves can move over long distances, the movement of the medium of transmission—the material—is limited. Therefore, the oscillating material does not move far from its initial equilibrium position. Mechanical waves transport energy. This energy propagates in the same direction as the wave. Any kind of wave (mechanical or electromagnetic) has a certain energy. Mechanical waves can be produced only in media which possess elasticity and inertia.\nMechanicsis the area of physics concerned with the motions of physical objects, more specifically the relationships among force, matter, and motion. Forces applied to objects result in displacements, or changes of an object's position relative to its environment.\nThis branch of physics has its origins in Ancient Greece with the writings of Aristotle and Archimedes (see History of classical mechanics and Timeline of classical mechanics). During the early modern period, scientists such as Galileo, Kepler, and Newton laid the foundation for what is now known as classical mechanics.\nIt is a branch of classical physics that deals with particles that are either at rest or are moving with velocities significantly less than the speed of light. \nIt can also be defined as a branch of science which deals with the motion of and forces on bodies not in the quantum realm. The field is today less widely understood in terms of quantum theory.\nMechanismis a device that transforms input forces and movement into a desired set of output forces and movement. Mechanisms generally consist of moving components which may include:\nGears and gear trains\nBelts and chain drives\nCams and followers\nLinkages\nFriction devices, such as brakes or clutches\nStructural components such as a frame, fasteners, bearings, springs, or lubricants\nVarious machine elements, such as splines, pins, or keys\nMedianIn statistics and probability theory, the median is the value separating the higher half from the lower half of a data sample, a population, or a probability distribution. For a data set, it may be thought of as \"the middle\" value. The basic feature of the median in describing data compared to the mean (often simply described as the \"average\") is that it is not skewed by a small proportion of extremely large or small values, and therefore provides a better representation of a \"typical\" value. Median income, for example, may be a better way to suggest what a \"typical\" income is, because income distribution can be very skewed. The median is of central importance in robust statistics, as it is the most resistant statistic, having a breakdown point of 50%: so long as no more than half the data are contaminated, the median is not an arbitrarily large or small result.\nMeltingMelting, or fusion, is a physical process that results in the phase transition of a substance from a solid to a liquid. This occurs when the internal energy of the solid increases, typically by the application of heat or pressure, which increases the substance's temperature to the melting point. At the melting point, the ordering of ions or molecules in the solid breaks down to a less ordered state, and the solid melts to become a liquid.\nMelting pointThe melting point (or, rarely, liquefaction point) of a substance is the temperature at which it changes state from solid to liquid. At the melting point the solid and liquid phase exist in equilibrium. The melting point of a substance depends on pressure and is usually specified at a standard pressure such as 1 atmosphere or 100 kPa.\n\nWhen considered as the temperature of the reverse change from liquid to solid, it is referred to as the freezing point or crystallization point. Because of the ability of substances to supercool, the freezing point can easily appear to be below its actual value. When the \"characteristic freezing point\" of a substance is determined, in fact the actual methodology is almost always \"the principle of observing the disappearance rather than the formation of ice, that is, the melting point.\"\nMesonIn particle physics, mesons are hadronic subatomic particles composed of an equal number of quarks and antiquarks, usually one of each, bound together by strong interactions. Because mesons are composed of quark subparticles, they have a meaningful physical size, a diameter of roughly one femtometer (1×10−15 m), which is about 0.6 times the size of a proton or neutron. All mesons are unstable, with the longest-lived lasting for only a few hundredths of a microsecond.  Heavier mesons decay to lighter mesons and ultimately to stable electrons, neutrinos and photons.\nMetallic bondingis a type of chemical bonding that arises from the electrostatic attractive force between conduction electrons (in the form of an electron cloud of delocalized electrons) and positively charged metal ions. It may be described as the sharing of free electrons among a structure of positively charged ions (cations). Metallic bonding accounts for many physical properties of metals, such as strength, ductility, thermal and electrical resistivity and conductivity, opacity, and luster.\n\nMetallic bonding is not the only type of chemical bonding a metal can exhibit, even as a pure substance. For example, elemental gallium consists of covalently-bound pairs of atoms in both liquid and solid-state—these pairs form a crystal structure with metallic bonding between them. Another example of a metal–metal covalent bond is the mercurous ion (Hg2+2).\nMiddle-out A combination of top-down and bottom-up design.\nMid-rangeIn statistics, the mid-range or mid-extreme is a measure of central tendency of a sample (statistics) defined as the arithmetic mean of the maximum and minimum values of the data set:\n\n  \n    \n      \n        M\n        =\n        \n          \n            \n              max\n              x\n              +\n              min\n              x\n            \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle M={\\frac {\\max x+\\min x}{2}}.}\n  \n\nThe mid-range is closely related to the range, a measure of statistical dispersion defined as the difference between maximum and minimum values.\nThe two measures are complementary in sense that if one knows the mid-range and the range, one can find the sample maximum and minimum values.\n\nThe mid-range is rarely used in practical statistical analysis, as it lacks efficiency as an estimator for most distributions of interest,  because it ignores all intermediate points, and lacks robustness, as outliers change it significantly. Indeed, it is one of the least efficient and least robust statistics. However, it finds some use in special cases: it is the maximally efficient estimator for the center of a uniform distribution, trimmed mid-ranges address robustness, and as an L-estimator, it is simple to understand and compute.\nMidhingeIn statistics, the midhinge is the average of the first and third quartiles and is thus a measure of location.\nEquivalently, it is the 25% trimmed mid-range or 25% midsummary; it is an L-estimator.\n\n  \n    \n      \n        MH\n        ⁡\n        (\n        X\n        )\n        =\n        \n          \n            \n              \n                Q\n                \n                  1\n                  ,\n                  3\n                \n              \n              (\n              X\n              )\n            \n            ¯\n          \n        \n        =\n        \n          \n            \n              \n                Q\n                \n                  1\n                \n              \n              (\n              X\n              )\n              +\n              \n                Q\n                \n                  3\n                \n              \n              (\n              X\n              )\n            \n            2\n          \n        \n        =\n        \n          \n            \n              \n                P\n                \n                  25\n                \n              \n              (\n              X\n              )\n              +\n              \n                P\n                \n                  75\n                \n              \n              (\n              X\n              )\n            \n            2\n          \n        \n        =\n        \n          M\n          \n            25\n          \n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle \\operatorname {MH} (X)={\\overline {Q_{1,3}(X)}}={\\frac {Q_{1}(X)+Q_{3}(X)}{2}}={\\frac {P_{25}(X)+P_{75}(X)}{2}}=M_{25}(X)}\n  \n\nThe midhinge is related to the interquartile range (IQR), the difference of the third and first quartiles (i.e. \n  \n    \n      \n        I\n        Q\n        R\n        =\n        \n          Q\n          \n            3\n          \n        \n        −\n        \n          Q\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle IQR=Q_{3}-Q_{1}}\n  \n), which is a measure of statistical dispersion. The two are complementary in sense that if one knows the midhinge and the IQR, one can find the first and third quartiles.\n\nThe use of the term \"hinge\" for the lower or upper quartiles derives from John Tukey's work on exploratory data analysis in the late 1970s, and \"midhinge\" is a fairly modern term dating from around that time. The midhinge is slightly simpler to calculate than the trimean (\n  \n    \n      \n        T\n        M\n      \n    \n    {\\displaystyle TM}\n  \n), which originated in the same context and equals the average of the median (\n  \n    \n      \n        \n          \n            \n              X\n              ~\n            \n          \n        \n        =\n        \n          Q\n          \n            2\n          \n        \n        =\n        \n          P\n          \n            50\n          \n        \n      \n    \n    {\\displaystyle {\\tilde {X}}=Q_{2}=P_{50}}\n  \n) and the midhinge.\n\n  \n    \n      \n        MH\n        ⁡\n        (\n        X\n        )\n        =\n        2\n        TM\n        ⁡\n        (\n        X\n        )\n        −\n        med\n        ⁡\n        (\n        X\n        )\n        =\n        2\n        \n          \n            \n              \n                Q\n                \n                  1\n                \n              \n              +\n              2\n              \n                Q\n                \n                  2\n                \n              \n              +\n              Q\n              3\n            \n            4\n          \n        \n        −\n        \n          Q\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\operatorname {MH} (X)=2\\operatorname {TM} (X)-\\operatorname {med} (X)=2{\\frac {Q_{1}+2Q_{2}+Q3}{4}}-Q_{2}}\n  \n\nMining engineeringMining in the engineering discipline is the extraction of minerals from underneath, above or on the ground. Mining engineering is associated with many other disciplines, such as mineral processing, exploration, excavation, geology, and metallurgy, geotechnical engineering and surveying. A mining engineer may manage any phase of mining operations, from exploration and discovery of the mineral resources, through feasibility study, mine design, development of plans, production and operations to mine closure.\nMiller indicesMiller indices form a notation system in crystallography for planes in crystal (Bravais) lattices.\n\nIn particular, a family of lattice planes is determined by three integers h, k, and ℓ, the Miller indices.  They are written (hkℓ), and denote the family of planes orthogonal to \n  \n    \n      \n        h\n        \n          \n            b\n            \n              1\n            \n          \n        \n        +\n        k\n        \n          \n            b\n            \n              2\n            \n          \n        \n        +\n        ℓ\n        \n          \n            b\n            \n              3\n            \n          \n        \n      \n    \n    {\\displaystyle h\\mathbf {b_{1}} +k\\mathbf {b_{2}} +\\ell \\mathbf {b_{3}} }\n  \n, where \n  \n    \n      \n        \n          \n            b\n            \n              i\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {b_{i}} }\n  \n are the basis of the reciprocal lattice vectors (note that the plane is not always orthogonal to the linear combination of direct lattice vectors \n  \n    \n      \n        h\n        \n          \n            a\n            \n              1\n            \n          \n        \n        +\n        k\n        \n          \n            a\n            \n              2\n            \n          \n        \n        +\n        ℓ\n        \n          \n            a\n            \n              3\n            \n          \n        \n      \n    \n    {\\displaystyle h\\mathbf {a_{1}} +k\\mathbf {a_{2}} +\\ell \\mathbf {a_{3}} }\n  \n because the  lattice vectors need not be mutually orthogonal). By convention, negative integers are written with a bar, as in 3 for −3.  The integers are usually written in lowest terms, i.e. their greatest common divisor should be 1. Miller indices are also used to designate reflections in X-ray crystallography. In this case the integers are not necessarily in lowest terms, and can be thought of as corresponding to planes spaced such that the reflections from adjacent planes would have a phase difference of exactly one wavelength (2π), regardless of whether there are atoms on all these planes or not.\n\nThere are also several related notations:\nthe notation {hkℓ} denotes the set of all planes that are equivalent to (hkℓ) by the symmetry of the lattice.\nIn the context of crystal directions (not planes), the corresponding notations are:\n[hkℓ], with square instead of round brackets, denotes a direction in the basis of the direct lattice vectors instead of the reciprocal lattice; and\nsimilarly, the notation <hkℓ> denotes the set of all directions that are equivalent to [hkℓ] by symmetry.\nMobile robotis a robot that is capable of moving in the surrounding (locomotion). Mobile robotics is usually considered to be a subfield of robotics and information engineering.\n\nMobile robots have the capability to move around in their environment and are not fixed to one physical location.  Mobile robots can be \"autonomous\" (AMR - autonomous mobile robot) which means they are capable of navigating an uncontrolled environment without the need for physical or electro-mechanical guidance devices.  Alternatively, mobile robots can rely on guidance devices that allow them to travel a pre-defined navigation route in relatively controlled space.  By contrast, industrial robots are usually more-or-less stationary, consisting of a jointed arm (multi-linked manipulator) and gripper assembly (or end effector), attached to a fixed surface. The joint-arm are controlled by linear actuator or servo motor or stepper motor.\nModeThe mode is the value that appears most often in a set of data values. If X is a discrete random variable, the mode is the value x  (i.e., X = x) at which the  probability mass function takes its maximum value. In other words, it is the value that is most likely to be sampled.\n\nLike the statistical mean and median, the mode is a way of expressing, in a (usually) single number, important information about a random variable or a population. The numerical value of the mode is the same as that of the mean and median in a normal distribution, and it may be very different in highly skewed distributions.\nModulus of elasticityAn elastic modulus (also known as modulus of elasticity) is a quantity that measures an object or substance's resistance to being deformed elastically (i.e., non-permanently) when a stress is applied to it. The elastic modulus of an object is defined as the slope of its stress–strain curve in the elastic deformation region: A stiffer material will have a higher elastic modulus. An elastic modulus has the form:\n\n  \n    \n      \n        δ\n         \n        \n          \n            \n              \n                =\n              \n              \n                def\n              \n            \n          \n        \n         \n        \n          \n            stress\n            strain\n          \n        \n      \n    \n    {\\displaystyle \\delta \\ {\\stackrel {\\text{def}}{=}}\\ {\\frac {\\text{stress}}{\\text{strain}}}}\n  \n\nwhere stress is the force causing the deformation divided by the area to which the force is applied and strain is the ratio of the change in some parameter caused by the deformation to the original value of the parameter. Since strain is a dimensionless quantity, the units of \n  \n    \n      \n        δ\n      \n    \n    {\\displaystyle \\delta }\n  \n will be the same as the units of stress.\nMohr's circle A graphical method of analyzing the three-dimensional stresses in  a system that has a loading force applied to it.\nMolalityis a measure of the number of moles of solute in a solution corresponding to 1 kg or 1000 g of solvent. This contrasts with the definition of molarity which is based on a specified volume of solution.\n\nA commonly used unit for molality in chemistry is mol/kg. A solution of concentration 1 mol/kg is also sometimes denoted as 1 molal. The unit mol/kg requires that molar mass be expressed in kg/mol, instead of the usual g/mol or kg/kmol.\n\nMolar attenuation coefficientis a measurement of how strongly a chemical species attenuates light at a given wavelength. It is an intrinsic property of the species. The SI unit of molar attenuation coefficient is the square metre per mole (m2/mol), but in practice, quantities are usually expressed in terms of M−1⋅cm−1 or L⋅mol−1⋅cm−1 (the latter two units are both equal to 0.1 m2/mol). In older literature, the cm2/mol is sometimes used; 1 M−1⋅cm−1 equals 1000 cm2/mol. The molar attenuation coefficient is also known as the molar extinction coefficient and molar absorptivity, but the use of these alternative terms has been discouraged by the IUPAC.\n\nMolar concentrationMolar concentration (also called molarity, amount concentration or substance concentration) is a measure of the concentration of a chemical species, in particular of a solute in a solution, in terms of amount of substance per unit volume of solution. In chemistry, the most commonly used unit for molarity is the number of moles per liter, having the unit symbol mol/L or mol⋅dm−3 in SI unit. A solution with a concentration of 1 mol/L is said to be 1 molar, commonly designated as 1 M. To avoid confusion with SI prefix mega, which has the same abbreviation, small caps ᴍ or italicized M are also used in journals and textbooks.\nMolar massIn chemistry, the molar mass of a chemical compound is defined as the mass of a sample of that compound divided by the amount of substance in that sample, measured in moles. It is the mass of 1 mole of the substance or 6.022×1023 particles, expressed in grams.  The molar mass is a bulk, not molecular, property of a substance. The molar mass is an average of many instances of the compound, which often vary in mass due to the presence of isotopes. Most commonly, the molar mass is computed from the standard atomic weights and is thus a terrestrial average and a function of the relative abundance of the isotopes of the constituent atoms on Earth. The molar mass is appropriate for converting between the mass of a substance and the amount of a substance for bulk quantities.\nMoldingMolding (American English) or moulding (British and Commonwealth English; see spelling differences) is the process of manufacturing by shaping liquid or pliable raw material using a rigid frame called a mold or matrix. This itself may have been made using a pattern or model of the final object.\nMoleculeA molecule is an electrically neutral group of two or more atoms held together by chemical bonds. Molecules are distinguished from ions by their lack of electrical charge.\n\nIn quantum physics, organic chemistry, and biochemistry, the distinction from ions is dropped and molecule is often used when referring to polyatomic ions.\n\nIn the kinetic theory of gases, the term molecule is often used for any gaseous particle regardless of its composition. This violates the definition that a molecule contain two or more atoms, since the noble gases are individual atoms.\n\nA molecule may be homonuclear, that is, it consists of atoms of one chemical element, as with two atoms in the oxygen molecule (O2); or it may be heteronuclear, a chemical compound composed of more than one element, as with water (two hydrogen atoms and one oxygen atom; H2O).\n\nAtoms and complexes connected by non-covalent interactions, such as hydrogen bonds or ionic bonds, are typically not considered single molecules.\nMolecular physicsis the study of the physical properties of molecules, the chemical bonds between atoms as well as the molecular dynamics.  Its most important experimental techniques are the various types of spectroscopy; scattering is also used. The field is closely related to atomic physics and overlaps greatly with theoretical chemistry, physical chemistry and chemical physics.\nMoment of inertiaThe moment of inertia, otherwise known as the mass moment of inertia, angular mass, second moment of mass, or most accurately, rotational inertia, of a rigid body is a quantity that determines the torque needed for a desired angular acceleration about a rotational axis, akin to how mass determines the force needed for a desired acceleration. It depends on the body's mass distribution and the axis chosen, with larger moments requiring more torque to change the body's rate of rotation.\nMultibody systemis the study of the dynamic behavior of interconnected rigid or flexible bodies, each of which may undergo large translational and rotational displacements.\nMultidisciplinary design optimization(MDO), is a field of engineering that uses optimization methods to solve design problems incorporating a number of disciplines. It is also known as multidisciplinary system design optimization (MSDO).\n\nMDO allows designers to incorporate all relevant disciplines simultaneously.  The optimum of the simultaneous problem is superior to the design found by optimizing each discipline sequentially, since it can exploit the interactions between the disciplines.  However, including all disciplines simultaneously significantly increases the complexity of the problem.\nMutual inductanceis the ratio between the electromotive force induced in one loop or coil by the rate of change of current in another loop or coil. Mutual inductance is given the symbol M.\nMuonThe muon, from the Greek letter mu (μ) used to represent it) is an elementary particle similar to the electron, with an electric charge of −1 e and a [[spin-1⁄2|spin of]] 1/2, but with a much greater mass. It is classified as a lepton. As with other leptons, the muon is not known to have any sub-structure – that is, it is not thought to be composed of any simpler particles.\n\nThe muon is an unstable subatomic particle with a mean lifetime of 2.2 μs, much longer than many other subatomic particles. As with the decay of the non-elementary neutron (with a lifetime around 15 minutes), muon decay is slow (by subatomic standards) because the decay is mediated only by the weak interaction (rather than the more powerful strong interaction or electromagnetic interaction), and because the mass difference between the muon and the set of its decay products is small, providing few kinetic degrees of freedom for decay. Muon decay almost always produces at least three particles, which must include an electron of the same charge as the muon and two types of neutrinos.\n\n\n== N ==\n\nNanoengineeringis the practice of engineering on the nanoscale. It derives its name from the nanometre, a unit of measurement equalling one billionth of a meter. Nanoengineering is largely a synonym for nanotechnology, but emphasizes the engineering rather than the pure science aspects of the field. \nNanotechnologyThe technology of systems built with moving parts on the order of a nanometre in size. \nNavier–Stokes equationsIn physics, the Navier–Stokes equations are a set of partial differential equations which describe the motion of viscous fluid substances, named after French engineer and physicist Claude-Louis Navier and Anglo-Irish physicist and mathematician George Gabriel Stokes.\nNeutrinoA neutrino (denoted by the Greek letter ν) is a fermion (an elementary particle with spin of ⁠1/2⁠) that interacts only via the weak subatomic force and gravity. The neutrino is so named because it is electrically neutral and because its rest mass is so small (-ino) that it was long thought to be zero. The mass of the neutrino is much smaller than that of the other known elementary particles. The weak force has a very short range, the gravitational interaction is extremely weak, and neutrinos do not participate in the strong interaction. Thus, neutrinos typically pass through normal matter unimpeded and undetected.\nNewtonian fluidis a fluid in which the viscous stresses arising from its flow, at every point, are linearly correlated to the local strain rate—the rate of change of its deformation over time. That is equivalent to saying those forces are proportional to the rates of change of the fluid's velocity vector as one moves away from the point in question in various directions. More precisely, a fluid is Newtonian only if the tensors that describe the viscous stress and the strain rate are related by a constant viscosity tensor that does not depend on the stress state and velocity of the flow. If the fluid is also isotropic (that is, its mechanical properties are the same along any direction), the viscosity tensor reduces to two real coefficients, describing the fluid's resistance to continuous shear deformation and continuous compression or expansion, respectively.\nNorton's theoremIn direct-current circuit theory, Norton's theorem (aka Mayer–Norton theorem) is a simplification that can be applied to networks made of linear time-invariant resistances, voltage sources, and current sources. At a pair of terminals of the network, it can be replaced by a current source and a single resistor in parallel. For alternating current (AC) systems the theorem can be applied to reactive impedances as well as resistances.\nNozzleis a device designed to control the direction or characteristics of a fluid flow (especially to increase velocity) as it exits (or enters) an enclosed chamber or pipe. A nozzle is often a pipe or tube of varying cross sectional area, and it can be used to direct or modify the flow of a fluid (liquid or gas). Nozzles are frequently used to control the rate of flow, speed, direction, mass, shape, and/or the pressure of the stream that emerges from them. In a nozzle, the velocity of fluid increases at the expense of its pressure energy.\nnth rootTo put a number of function to the exponential power of 1/n. \nNuclear binding energyThe difference between the total mass energy of a nucleus and the mass energy of the isolated nucleons.\nNuclear engineeringThe profession that deals with nuclear power.\nNuclear fusionis a reaction in which two or more atomic nuclei are combined to form one or more different atomic nuclei and subatomic particles (neutrons or protons). The difference in mass between the reactants and products is manifested as either the release or the absorption of energy. This difference in mass arises due to the difference in atomic binding energy between the nuclei before and after the reaction. Fusion is the process that powers active or main sequence stars and other high-magnitude stars, where large amounts of energy are released.\nNuclear physicsThe science that describes the components of atoms.\nNuclear potential energyThe energy that is given up in decay of an unstable nucleus.\nNuclear powerThe use of energy derived from nuclear chain reactions for electricity production or ship propulsion.\n\n\n== O ==\n\nOhmThe SI unit of electrical resistance. \nOhm's lawA law describing the relationship between resistance, current, and voltage. \nOpticsThe study of light.\nOrganic chemistryThe study of carbon compounds.\nOsmosisThe spontaneous movement of molecules or ions through a semi-permable membrane, tending to equalize concentration on both sides.\n\n\n== P ==\n\nParallel circuitA circuit that begins and ends at the same node as another circuit. \nParity (mathematics)In mathematics, parity is the property of an integer of whether it is even or odd. An integer's parity is even if it is divisible by two with no remainders left and its parity is odd if its remainder is 1. For example, -4, 0, 82, and 178 are even because there is no remainder when dividing it by 2. By contrast, -3, 5, 7, 21 are odd numbers as they leave a remainder of 1 when divided by 2.\nParity (physics)In quantum mechanics, a parity transformation (also called parity inversion) is the flip in the sign of one spatial coordinate. In three dimensions, it can also refer to the simultaneous flip in the sign of all three spatial coordinates (a point reflection):\n\n  \n    \n      \n        \n          P\n        \n        :\n        \n          \n            (\n            \n              \n                \n                  x\n                \n              \n              \n                \n                  y\n                \n              \n              \n                \n                  z\n                \n              \n            \n            )\n          \n        \n        ↦\n        \n          \n            (\n            \n              \n                \n                  −\n                  x\n                \n              \n              \n                \n                  −\n                  y\n                \n              \n              \n                \n                  −\n                  z\n                \n              \n            \n            )\n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {P} :{\\begin{pmatrix}x\\\\y\\\\z\\end{pmatrix}}\\mapsto {\\begin{pmatrix}-x\\\\-y\\\\-z\\end{pmatrix}}.}\n  \n\nIt can also be thought of as a test for chirality of a physical phenomenon, in that a parity inversion transforms a phenomenon into its mirror image. All fundamental interactions of elementary particles, with the exception of the weak interaction, are symmetric under parity. The weak interaction is chiral and thus provides a means for probing chirality in physics. In interactions that are symmetric under parity, such as electromagnetism in atomic and molecular physics, parity serves as a powerful controlling principle underlying quantum transitions.\n\nA matrix representation of P (in any number of dimensions) has determinant equal to −1, and hence is distinct from a rotation, which has a determinant equal to 1. In a two-dimensional plane, a simultaneous flip of all coordinates in sign is not a parity transformation; it is the same as a 180°-rotation.\n\nIn quantum mechanics, wave functions that are unchanged by a parity transformation are described as even functions, while those that change sign under a parity transformation are odd functions.fn=A hydrocarbon compound, solid at room temperature. \nParamagnetismis a form of magnetism whereby some materials are weakly attracted by an externally applied magnetic field, and form internal, induced magnetic fields in the direction of the applied magnetic field. In contrast with this behavior, diamagnetic materials are repelled by magnetic fields and form induced magnetic fields in the direction opposite to that of the applied magnetic field. Paramagnetic materials include most chemical elements and some compounds; they have a relative magnetic permeability slightly greater than 1 (i.e., a small positive magnetic susceptibility) and hence are attracted to magnetic fields. The magnetic moment induced by the applied field is linear in the field strength and rather weak. It typically requires a sensitive analytical balance to detect the effect and modern measurements on paramagnetic materials are often conducted with a SQUID magnetometer.\nParticle acceleratoris a machine that uses electromagnetic fields to propel charged particles to very high speeds and energies, and to contain them in well-defined beams.\nParticle displacementParticle displacement or displacement amplitude is a measurement of distance of the movement of a sound particle from its equilibrium position in a medium as it transmits a sound wave. \nThe SI unit of particle displacement is the meter (m). In most cases this is a longitudinal wave of pressure (such as sound), but it can also be a transverse wave, such as the vibration of a taut string. In the case of a sound wave travelling through air, the particle displacement is evident in the oscillations of air molecules with, and against, the direction in which the sound wave is travelling.\nParticle physicsParticle physics (also known as high energy physics) is a branch of physics that studies the nature of the particles that constitute matter and radiation. Although the word particle can refer to various types of very small objects (e.g. protons, gas particles, or even household dust), particle physics usually investigates the irreducibly smallest detectable particles and the fundamental interactions necessary to explain their behaviour. In current understanding, these elementary particles are excitations of the quantum fields that also govern their interactions. The currently dominant theory explaining these fundamental particles and fields, along with their dynamics, is called the Standard Model. Thus, modern particle physics generally investigates the Standard Model and its various possible extensions, e.g. to the newest \"known\" particle, the Higgs boson, or even to the oldest known force field, gravity.\nPascal's lawPascal's law (also Pascal's principle or the principle of transmission of fluid-pressure) is a principle in fluid mechanics that states that a pressure change occurring anywhere in a confined incompressible fluid is transmitted throughout the fluid such that the same change occurs everywhere. The law was established by French mathematician Blaise Pascal in 1647–48.\nPendulumIs a weight suspended from a pivot so that it can swing freely. When a pendulum is displaced sideways from its resting, equilibrium position, it is subject to a restoring force due to gravity that will accelerate it back toward the equilibrium position. When released, the restoring force acting on the pendulum's mass causes it to oscillate about the equilibrium position, swinging back and forth. The time for one complete cycle, a left swing and a right swing, is called the period. The period depends on the length of the pendulum and also to a slight degree on the amplitude, the width of the pendulum's swing.\nPetroleum engineeringis a field of engineering concerned with the activities related to the production of hydrocarbons, which can be either crude oil or natural gas. Exploration and production are deemed to fall within the upstream sector of the oil and gas industry. Exploration, by earth scientists, and petroleum engineering are the oil and gas industry's two main subsurface disciplines, which focus on maximizing economic recovery of hydrocarbons from subsurface reservoirs. Petroleum geology and geophysics focus on provision of a static description of the hydrocarbon reservoir rock, while petroleum engineering focuses on estimation of the recoverable volume of this resource using a detailed understanding of the physical behavior of oil, water and gas within porous rock at very high pressure.\npHA logarithmic measure of the concentration of  hydrogen ions in an acid or base solution. \nPhase (matter)In the physical sciences, a phase is a region of space (a thermodynamic system), throughout which all physical properties of a material are essentially uniform.: 86 : 3  Examples of physical properties include density, index of refraction, magnetization and chemical composition. A simple description is that a phase is a region of material that is chemically uniform, physically distinct, and (often) mechanically separable. In a system consisting of ice and water in a glass jar, the ice cubes are one phase, the water is a second phase, and the humid air is a third phase over the ice and water. The glass of the jar is another separate phase. (See state of matter § Glass)\nPhase (waves)In physics and mathematics, the phase of a periodic function \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n of some real variable \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n (such as time) is an angle-like quantity representing the fraction of the cycle covered up to \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n.  It is denoted \n  \n    \n      \n        ϕ\n        (\n        t\n        )\n      \n    \n    {\\displaystyle \\phi (t)}\n  \n and expressed in such a scale that it varies by one full turn as the variable \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n goes through each period (and \n  \n    \n      \n        F\n        (\n        t\n        )\n      \n    \n    {\\displaystyle F(t)}\n  \n goes through each complete cycle).  It may be measured in any angular unit such as degrees or radians, thus increasing by 360° or \n  \n    \n      \n        2\n        π\n      \n    \n    {\\displaystyle 2\\pi }\n  \n as the variable \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n completes a full period.\nPhase diagramA phase diagram in physical chemistry, engineering, mineralogy, and materials science is a type of chart used to show conditions (pressure, temperature, volume, etc.) at which thermodynamically distinct phases (such as solid, liquid or gaseous states) occur and coexist at equilibrium. \nPhase ruleIn thermodynamics, the phase rule is a general principle governing \"pVT\" systems (that is, systems whose states are completely described by the variables pressure (p), volume (V) and temperature (T)) in thermodynamic equilibrium. If F is the number of degrees of freedom, C is the number of components and P is the number of phases, then \n\n  \n    \n      \n        F\n        =\n        C\n        −\n        P\n        +\n        2.\n      \n    \n    {\\displaystyle F=C-P+2.}\n  \n\nIt was derived by American physicist Josiah Willard Gibbs in his landmark paper titled On the Equilibrium of Heterogeneous Substances, published in parts between 1875 and 1878.\nThe rule assumes the components do not react with each other.\nPhotonis a type of elementary particle. It is the quantum of the electromagnetic field including electromagnetic radiation such as light and radio waves, and the force carrier for the electromagnetic force. Photons are massless, so they always move at the speed of light in vacuum, 299792458 m/s (or about 186,282 mi/s). The photon belongs to the class of bosons.\nPhysical chemistryis the study of macroscopic, and particulate phenomena in chemical systems in terms of the principles, practices, and concepts of physics such as motion, energy, force, time, thermodynamics, quantum chemistry, statistical mechanics, analytical dynamics and chemical equilibrium.\nPhysical quantityA physical quantity is a property of a material or system that can be quantified by measurement. A physical quantity can be expressed as a value, which is the algebraic multiplication of a numerical value and a unit. For example, the physical quantity mass can be quantified as n kg, where n is the numerical value and kg is the unit. A physical quantity possesses at least two characteristics in common. One is numerical magnitude and the other is the unit in which it is measured.\nPhysicsis the natural science that studies matter, its motion and behavior through space and time, and the related entities of energy and force. Physics is one of the most fundamental scientific disciplines, and its main goal is to understand how the universe behaves.\nPlanck constantThe Planck constant, or Planck's constant, is a fundamental physical constant denoted \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n  \n, and is of fundamental importance in quantum mechanics. A photon's energy is equal to its frequency multiplied by the Planck constant.  Due to mass–energy equivalence, the Planck constant also relates mass to frequency.\n\nIn metrology it is used, together with other constants, to define the kilogram, an SI unit. The SI units are defined in such a way that, when the Planck constant is expressed in SI units, it has the exact value \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n  \n = 6.62607015×10−34 J⋅Hz−1.\nPlasma (physics)Is one of the four fundamental states of matter, first systematically studied by Irving Langmuir in the 1920s. It consists of a gas of ions – atoms or molecules which have one or more orbital electrons stripped (or, rarely, an extra electron attached), and free electrons.\nPlasticityIn physics and materials science, plasticity, also known as plastic deformation, is the ability of a solid material to undergo permanent deformation, a non-reversible change of shape in response to applied forces.  For example, a solid piece of metal being bent or pounded into a new shape displays plasticity as permanent changes occur within the material itself. In engineering, the transition from elastic behavior to plastic behavior is known as yielding.\nPneumaticsThe control of mechanical force and movement, generated by the application of compressed gas.\nPoint estimationIn statistics, point estimation involves the use of sample data to calculate a single value (known as a point estimate since it identifies a point in some parameter space) which is to serve as a \"best guess\" or \"best estimate\" of an unknown population parameter (for example, the population mean). More formally, it is the application of a point estimator to the data to obtain a point estimate.\n\nPoint estimation can be contrasted with interval estimation: such interval estimates are typically either confidence intervals, in the case of frequentist inference, or credible intervals, in the case of Bayesian inference. More generally, a point estimator can be contrasted with a set estimator. Examples are given by confidence sets or credible sets. A point estimator can also be contrasted with a distribution estimator. Examples are given by confidence distributions, randomized estimators, and Bayesian posteriors. \nPolyphase systemAn electrical system that uses a set of alternating currents at different phases. \nPower (electric)Electric power is the rate, per unit time, at which electrical energy is transferred by an electric circuit. The SI unit of power is the watt, one joule per second.\n\nElectric power is usually produced by electric generators, but can also be supplied by sources such as electric batteries.  It is usually supplied to businesses and homes (as domestic mains electricity) by the electric power industry through an electric power grid.\n\nElectric power can be delivered over long distances by transmission lines and used for applications such as motion, light or heat with high efficiency.\nPower (physics)In physics, power is the amount of energy transferred or converted per unit time. In the International System of Units, the unit of power is the watt, equal to one joule per second. In older works, power is sometimes called activity. Power is a scalar quantity. \nPower factorIn electrical engineering, the power factor of an AC power system is defined as the ratio of the real power absorbed by the load to the apparent power flowing in the circuit, and is a dimensionless number in the closed interval of −1 to 1. A power factor of less than one indicates the voltage and current are not in phase, reducing the average product of the two. Real power is the instantaneous product of voltage and current and represents the capacity of the electricity for performing work. Apparent power is the product of RMS current and voltage. Due to energy stored in the load and returned to the source, or due to a non-linear load that distorts the wave shape of the current drawn from the source, the apparent power may be greater than the real power. A negative power factor occurs when the device (which is normally the load) generates power, which then flows back towards the source. \nPressurePressure (symbol: p or P) is the force applied perpendicular to the surface of an object per unit area over which that force is distributed.: 445  Gauge pressure (also spelled gage pressure) is the pressure relative to the ambient pressure.\n\nVarious units are used to express pressure. Some of these derive from a unit of force divided by a unit of area; the SI unit of pressure, the pascal (Pa), for example, is one newton per square metre (N/m2); similarly, the pound-force per square inch (psi) is the traditional unit of pressure in the imperial and U.S. customary systems. Pressure may also be expressed in terms of standard atmospheric pressure; the atmosphere (atm) is equal to this pressure, and the torr is defined as 1⁄760 of this. Manometric units such as the centimetre of water, millimetre of mercury, and inch of mercury are used to express pressures in terms of the height of column of a particular fluid in a manometer. \nProbabilityis the branch of mathematics concerning numerical descriptions of how likely an event is to occur, or how likely it is that a proposition is true.  The probability of an event is a number between 0 and 1, where, roughly speaking, 0 indicates impossibility of the event and 1 indicates certainty. The higher the probability of an event, the more likely it is that the event will occur. A simple example is the tossing of a fair (unbiased) coin. Since the coin is fair, the two outcomes (\"heads\" and \"tails\") are both equally probable; the probability of \"heads\" equals the probability of \"tails\"; and since no other outcomes are possible, the probability of either \"heads\" or \"tails\" is 1/2 (which could also be written as 0.5 or 50%). \nProbability distributionIn probability theory and statistics, a probability distribution is the mathematical function that gives the probabilities of occurrence of different possible outcomes for an experiment. It is a mathematical description of a random phenomenon in terms of its sample space and the probabilities of events (subsets of the sample space).\n\nFor instance, if X is used to denote the outcome of a coin toss (\"the experiment\"), then the probability distribution of X would take the value 0.5 (1 in 2 or 1/2) for X = heads, and 0.5 for X = tails (assuming that the coin is fair). Examples of random phenomena include the weather condition in a future date, the height of a randomly selected person, the fraction of male students in a school, the results of a survey to be conducted, etc. \nProbability theoryis the branch of mathematics concerned with probability. Although there are several different probability interpretations, probability theory treats the concept in a rigorous mathematical manner by expressing it through a set of axioms. Typically these axioms formalise probability in terms of a probability space, which assigns a measure taking values between 0 and 1, termed the probability measure, to a set of outcomes called the sample space. Any specified subset of these outcomes is called an event.\nCentral subjects in probability theory include discrete and continuous random variables, probability distributions, and stochastic processes, which provide mathematical abstractions of non-deterministic or uncertain processes or measured quantities that may either be single occurrences or evolve over time in a random fashion.\nAlthough it is not possible to perfectly predict random events, much can be said about their behavior. Two major results in probability theory describing such behaviour are the law of large numbers and the central limit theorem.\n\nAs a mathematical foundation for statistics, probability theory is essential to many human activities that involve quantitative analysis of data. Methods of probability theory also apply to descriptions of complex systems given only partial knowledge of their state, as in statistical mechanics or sequential estimation. A great discovery of twentieth-century physics was the probabilistic nature of physical phenomena at atomic scales, described in quantum mechanics. \n\nProcess\n\nPulleyis a wheel on an axle or shaft that is designed to support movement and change of direction of a taut cable or belt, or transfer of power between the shaft and cable or belt. In the case of a pulley supported by a frame or shell that does not transfer power to a shaft, but is used to guide the cable or exert a force, the supporting shell is called a block, and the pulley may be called a sheave.\n\nA pulley may have a groove or grooves between flanges around its circumference to locate the cable or belt. The drive element of a pulley system can be a rope, cable, belt, or chain.\nPumpis a device that moves fluids (liquids or gases), or sometimes slurries, by mechanical action, typically converted from electrical energy into hydraulic energy. Pumps can be classified into three major groups according to the method they use to move the fluid: direct lift, displacement, and gravity pumps.\n\nPumps operate by some mechanism (typically reciprocating or rotary), and consume energy to perform mechanical work moving the fluid. Pumps operate via many energy sources, including manual operation, electricity, engines, or wind power, and come in many sizes, from microscopic for use in medical applications, to large industrial pumps.\n\n\n== Q ==\n\nQuantum electrodynamicsIn particle physics, quantum electrodynamics (QED) is the relativistic quantum field theory of electrodynamics. In essence, it describes how light and matter interact and is the first theory where full agreement between quantum mechanics and special relativity is achieved. QED mathematically describes all phenomena involving electrically charged particles interacting by means of exchange of photons and represents the quantum counterpart of classical electromagnetism giving a complete account of matter and light interaction.\nQuantum field theoryIn theoretical physics, quantum field theory (QFT) is a theoretical framework that combines classical field theory, special relativity and quantum mechanics,: xi  but not general relativity's description of gravity. QFT is used in particle physics to construct physical models of subatomic particles and in condensed matter physics to construct models of quasiparticles.\nQuantum mechanicsis a fundamental theory in physics that provides a description of the physical properties of nature at the scale of atoms and subatomic particles.: 1.1  It is the foundation of all quantum physics including quantum chemistry, quantum field theory, quantum technology, and quantum information science.\n\n\n== R ==\n\nRegelationThe phenomena of melting under pressure, then freezing when the pressure is reduced. \nRelative densityRelative density, or specific gravity, is the ratio of the density (mass of a unit volume) of a substance to the density of a given reference material. Specific gravity for liquids is nearly always measured with respect to water at its densest (at 4 °C or 39.2 °F); for gases, the reference is air at room temperature (20 °C or 68 °F). The term \"relative density\" is often preferred in scientific usage. \nRelative velocityThe relative velocity \n  \n    \n      \n        \n          \n            \n              \n                v\n                →\n              \n            \n          \n          \n            B\n            ∣\n            A\n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{B\\mid A}}\n  \n (also \n  \n    \n      \n        \n          \n            \n              \n                v\n                →\n              \n            \n          \n          \n            B\n            A\n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{BA}}\n  \n or \n  \n    \n      \n        \n          \n            \n              \n                v\n                →\n              \n            \n          \n          \n            B\n            rel\n            ⁡\n            A\n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{B\\operatorname {rel} A}}\n  \n) is the velocity of an object or observer B in the rest frame of another object or observer A.\nReliability engineeringis a sub-discipline of systems engineering that emphasizes the ability of equipment to function without failure. Reliability describes the ability of a system or component to function under stated conditions for a specified period of time. Reliability is closely related to availability, which is typically described as the ability of a component or system to function at a specified moment or interval of time.\nResistivityElectrical resistivity (also called specific electrical resistance or volume resistivity) and its inverse, electrical conductivity, is a fundamental property of  a material that quantifies how strongly it resists or conducts electric current. A low resistivity indicates a material that readily allows electric current. Resistivity is commonly represented by the Greek letter ρ (rho). The SI unit of electrical resistivity is the ohm-meter (Ω⋅m). For example, if a 1 m × 1 m × 1 m solid cube of material has sheet contacts on two opposite faces, and the resistance between these contacts is 1 Ω, then the resistivity of the material is 1 Ω⋅m.\nResistoris a passive two-terminal electrical component that implements electrical resistance as a circuit element. In electronic circuits, resistors are used to reduce current flow, adjust signal levels, to divide voltages, bias active elements, and terminate transmission lines, among other uses. High-power resistors that can dissipate many watts of electrical power as heat, may be used as part of motor controls, in power distribution systems, or as test loads for generators.\nFixed resistors have resistances that only change slightly with temperature, time or operating voltage. Variable resistors can be used to adjust circuit elements (such as a volume control or a lamp dimmer), or as sensing devices for heat, light, humidity, force, or chemical activity.\nReynolds numberThe Reynolds number (Re) helps predict flow patterns in different fluid flow situations. At low Reynolds numbers, flows tend to be dominated by laminar (sheet-like) flow, while at high Reynolds numbers flows tend to be turbulent. The turbulence results from differences in the fluid's speed and direction, which may sometimes intersect or even move counter to the overall direction of the flow (eddy currents). These eddy currents begin to churn the flow, using up energy in the process, which for liquids increases the chances of cavitation. Reynolds numbers are an important dimensionless quantity in fluid mechanics.\nRheologyis the study of the flow of matter, primarily in a liquid or gas state, but also as \"soft solids\" or solids under conditions in which they respond with plastic flow rather than deforming elastically in response to an applied force. Rheology is a branch of physics, and it is the science that deals with the deformation and flow of materials, both solids and liquids.\nRigid bodyIn physics, a rigid body (also known as a rigid object ) is a solid body in which deformation is zero or so small it can be neglected. The distance between any two given points on a rigid body remains constant in time regardless of external forces or moments exerted on it. A rigid body is usually considered as a continuous distribution of mass. In the study of special relativity, a perfectly rigid body does not exist; and objects can only be assumed to be rigid if they are not moving near the speed of light. In quantum mechanics, a rigid body is usually thought of as a collection of point masses. For instance, molecules (consisting of the point masses: electrons and nuclei) are often seen as rigid bodies (see classification of molecules as rigid rotors).\nRobonautA development project conducted by NASA to create humanoid robots capable of using space tools and working in similar environments to suited astronauts.\nRobot-assisted surgeryRobotic surgeries are types of surgical procedures that are done using robotic systems. Robotically-assisted surgery was developed to try to overcome the limitations of pre-existing minimally-invasive surgical procedures and to enhance the capabilities of surgeons performing open surgery.\n\nIn the case of robotically-assisted minimally-invasive surgery, instead of directly moving the instruments, the surgeon uses one of two methods to administer the instruments. These include using a direct telemanipulator or through computer control. A telemanipulator is a remote manipulator that allows the surgeon to perform the normal movements associated with the surgery. The robotic arms carry out those movements using end-effectors and manipulators to perform the actual surgery. In computer-controlled systems, the surgeon uses a computer to control the robotic arms and its end-effectors, though these systems can also still use telemanipulators for their input. One advantage of using the computerized method is that the surgeon does not have to be present, leading to the possibility for remote surgery.\nRoboticsIs an interdisciplinary field that integrates computer science and engineering. Robotics involves design, construction, operation, and use of robots. The goal of robotics is to design machines that can help and assist humans. Robotics integrates fields of mechanical engineering, electrical engineering, information engineering, mechatronics, electronics, bioengineering, computer engineering, control engineering, software engineering, among others.\nRoot mean squareIn mathematics and its applications, the root mean square (RMS or rms) is defined as the square root of the mean square (the arithmetic mean of the squares of a set of numbers).\nThe RMS is also known as the quadratic mean and is a particular case of the generalized mean with exponent 2. RMS can also be defined for a continuously varying function in terms of an integral of the squares of the instantaneous values during a cycle. For alternating electric current, RMS is equal to the value of the constant direct current that would produce the same power dissipation in a resistive load. In estimation theory, the root-mean-square deviation of an estimator is a measure of the imperfection of the fit of the estimator to the data.\nRoot-mean-square speedIn the physics of gas molecules, the root-mean-square speed is defined as the square root of the average squared-speed. The RMS speed of an ideal gas is calculated using the following equation:\n\n  \n    \n      \n        \n          v\n          \n            RMS\n          \n        \n        =\n        \n          \n            \n              \n                3\n                R\n                T\n              \n              M\n            \n          \n        \n      \n    \n    {\\displaystyle v_{\\text{RMS}}={\\sqrt {3RT \\over M}}}\n  \n\nwhere R represents the gas constant, 8.314 J/(mol·K), T is the temperature of the gas in kelvins, and M is the molar mass of the gas in kilograms per mole. In physics, speed is defined as the scalar magnitude of velocity. For a stationary gas, the average speed of its molecules can be in the order of thousands of km/h, even though the average velocity of its molecules is zero.\nRotational energyRotational energy or angular kinetic energy is kinetic energy due to the rotation of an object and is part of its total kinetic energy. Looking at rotational energy separately around an object's axis of rotation, the following dependence on the object's moment of inertia is observed:\n\n  \n    \n      \n        \n          E\n          \n            \n              r\n              o\n              t\n              a\n              t\n              i\n              o\n              n\n              a\n              l\n            \n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        I\n        \n          ω\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{\\mathrm {rotational} }={\\frac {1}{2}}I\\omega ^{2}}\n  \n\nwhere\n\n  \n    \n      \n        ω\n         \n      \n    \n    {\\displaystyle \\omega \\ }\n  \n is the angular velocity\n\n  \n    \n      \n        I\n         \n      \n    \n    {\\displaystyle I\\ }\n  \n is the moment of inertia around the axis of rotation\n\n  \n    \n      \n        E\n         \n      \n    \n    {\\displaystyle E\\ }\n  \n is the kinetic energy\nRotational speedRotational speed (or speed of revolution) of an object rotating around an axis is the number of turns of the object divided by time, specified as revolutions per minute (rpm), cycles per second (cps), radians per second (rad/s), etc.\n\nThe symbol for rotational speed is \n  \n    \n      \n        \n          ω\n          \n            cyc\n          \n        \n      \n    \n    {\\displaystyle \\omega _{\\text{cyc}}}\n  \n(the Greek lowercase letter \"omega\").\n\nTangential speed v, rotational speed \n  \n    \n      \n        \n          ω\n          \n            cyc\n          \n        \n      \n    \n    {\\displaystyle \\omega _{\\text{cyc}}}\n  \n, and radial distance r, are related by the following equation:\n\n  \n    \n      \n        v\n        =\n        2\n        π\n        r\n        \n          ω\n          \n            cyc\n          \n        \n      \n    \n    {\\displaystyle v=2\\pi r\\omega _{\\text{cyc}}}\n  \n\n  \n    \n      \n        v\n        =\n        r\n        \n          ω\n          \n            rad\n          \n        \n      \n    \n    {\\displaystyle v=r\\omega _{\\text{rad}}}\n  \n\nAn algebraic rearrangement of this equation allows us to solve for rotational speed:\n\n  \n    \n      \n        \n          ω\n          \n            cyc\n          \n        \n        =\n        v\n        \n          /\n        \n        2\n        π\n        r\n      \n    \n    {\\displaystyle \\omega _{\\text{cyc}}=v/2\\pi r}\n  \n\n  \n    \n      \n        \n          ω\n          \n            rad\n          \n        \n        =\n        v\n        \n          /\n        \n        r\n      \n    \n    {\\displaystyle \\omega _{\\text{rad}}=v/r}\n  \n\nThus, the tangential speed will be directly proportional to r when all parts of a system simultaneously have the same ω, as for a wheel, disk, or rigid wand. The direct proportionality of v to r is not valid for the planets, because the planets have different rotational speeds (ω).\n\nRotational speed can measure, for example, how fast a motor is running. Rotational speed and angular speed are sometimes used as synonyms, but typically they are measured with a different unit. Angular speed, however, tells the change in angle per time unit, which is measured in radians per second in the SI system. Since there are 2π radians per cycle, or 360 degrees per cycle, we can convert angular speed to rotational speed by\n\n  \n    \n      \n        \n          ω\n          \n            cyc\n          \n        \n        =\n        \n          ω\n          \n            rad\n          \n        \n        \n          /\n        \n        2\n        π\n        \n      \n    \n    {\\displaystyle \\omega _{\\text{cyc}}=\\omega _{\\text{rad}}/2\\pi \\,}\n  \n\nand\n\n  \n    \n      \n        \n          ω\n          \n            cyc\n          \n        \n        =\n        \n          ω\n          \n            deg\n          \n        \n        \n          /\n        \n        360\n        \n      \n    \n    {\\displaystyle \\omega _{\\text{cyc}}=\\omega _{\\text{deg}}/360\\,}\n  \n\nwhere\n\n  \n    \n      \n        \n          ω\n          \n            cyc\n          \n        \n        \n      \n    \n    {\\displaystyle \\omega _{\\text{cyc}}\\,}\n  \n is rotational speed in cycles per second\n\n  \n    \n      \n        \n          ω\n          \n            rad\n          \n        \n        \n      \n    \n    {\\displaystyle \\omega _{\\text{rad}}\\,}\n  \n is angular speed in radians per second\n\n  \n    \n      \n        \n          ω\n          \n            deg\n          \n        \n        \n      \n    \n    {\\displaystyle \\omega _{\\text{deg}}\\,}\n  \n is angular speed in degrees per second\n\nFor example, a stepper motor might turn exactly one complete revolution each second.\nIts angular speed is 360 degrees per second (360°/s), or 2π radians per second (2π rad/s), while the rotational speed is 60 rpm.\n\nRotational speed is not to be confused with tangential speed, despite some relation between the two concepts. Imagine a rotating merry-go-round. No matter how close or far one stands from the axis of rotation, the rotational speed will remain constant. However, tangential speed does not remain constant. If one stands two meters from the axis of rotation, the tangential speed will be double the amount if one were standing only one meter from the axis of rotation.\n\n\n== S ==\n\nSafe failure fraction (SFF)A term used in functional safety for the proportion of failures that are either non-hazardous or detected automatically. The opposite of SFF is the proportion of undetected, hazardous failures.\nSafety data sheetA safety data sheet (SDS), material safety data sheet (MSDS),  or product safety data sheet (PSDS) are documents that list information relating to occupational safety and health for the use of various substances and products. SDSs are a widely used system for cataloguing information on chemicals, chemical compounds, and chemical mixtures. SDS information may include instructions for the safe use and potential hazards associated with a particular material or product, along with spill-handling procedures. The older MSDS formats could vary from source to source within a country depending on national requirements; however, the newer SDS format is internationally standardized.\nSanitary engineeringSanitary engineering, also known as public health engineering or wastewater engineering, is the application of engineering methods to improve sanitation of human communities, primarily by providing the removal and disposal of human waste, and in addition to the supply of safe potable water.\nSaturated compoundIn chemistry, a saturated compound is a chemical compound (or ion) that resists the addition reactions, such as hydrogenation, oxidative addition, and binding of a Lewis base. The term is used in many contexts and for many classes of chemical compounds. Overall, saturated compounds are less reactive than unsaturated compounds. Saturation is derived from the Latin word saturare, meaning 'to fill')\nScalar (mathematics).\nScalar (physics).\nScalar multiplicationIn mathematics, scalar multiplication is one of the basic operations defining a vector space in linear algebra (or more generally, a module in abstract algebra). In common geometrical contexts, scalar multiplication of a real Euclidean vector by a positive real number multiplies the magnitude of the vector—without changing its direction. The term \"scalar\" itself derives from this usage: a scalar is that which scales vectors. Scalar multiplication is the multiplication of a vector by a scalar (where the product is a vector), and is to be distinguished from inner product of two vectors (where the product is a scalar).\nScrewA screw is a mechanism that converts rotational motion to linear motion, and a torque (rotational force) to a linear force. It is one of the six classical simple machines. The most common form consists of a cylindrical shaft with helical grooves or ridges called threads around the outside. The screw passes through a hole in another object or medium, with threads on the inside of the hole that mesh with the screw's threads. When the shaft of the screw is rotated relative to the stationary threads, the screw moves along its axis relative to the medium surrounding it; for example rotating a wood screw forces it into wood. In screw mechanisms, either the screw shaft can rotate through a threaded hole in a stationary object, or a threaded collar such as a nut can rotate around a stationary screw shaft.  Geometrically, a screw can be viewed as a narrow inclined plane wrapped around a cylinder.\nSeries circuitAn electrical circuit in which the same current passes through each component, with only one path.\nServoA motor that moves to and maintains a set position under command, rather than continuously moving. \nServomechanismAn automatic device that uses error-sensing negative feedback to correct the performance of a mechanism. \nShadow matterIn physics, mirror matter, also called shadow matter or Alice matter, is a hypothetical counterpart to ordinary matter.\nShear flowThe term shear flow is used in solid mechanics as well as in fluid dynamics.  The expression shear flow is used to indicate:\na shear stress over a distance in a thin-walled structure (in solid mechanics);\nthe flow induced by a force (in a fluid).\nShear strengthis the strength of a material or component against the type of yield or structural failure when the material or component fails in shear. A shear load is a force that tends to produce a sliding failure on a material along a plane that is parallel to the direction of the force. When a paper is cut with scissors, the paper fails in shear.\n\nIn structural and  mechanical engineering, the shear strength of a component is important for designing the dimensions and materials to be used for the manufacture or construction of the component (e.g. beams, plates, or bolts). In a reinforced concrete beam, the main purpose of reinforcing bar (rebar) stirrups is to increase the shear strength.\nShear stressShear stress, often denoted by τ (Greek: tau), is the component of stress coplanar with a material cross section. It arises from the shear force, the component of force vector parallel to the material cross section.  Normal stress, on the other hand, arises from the force vector component perpendicular to the material cross section on which it acts.\nShortwave radiationShortwave radiation (SW) is radiant energy with wavelengths in the visible (VIS), near-ultraviolet (UV), and near-infrared (NIR) spectra.\n\nThere is no standard cut-off for the near-infrared range; therefore, the shortwave radiation range is also variously defined. It may be broadly defined to include all radiation with a wavelength of 0.1μm and 5.0μm or narrowly defined so as to include only radiation between 0.2μm and 3.0μm.\n\nThere is little radiation flux (in terms of W/m2) to the Earth's surface below 0.2μm or above 3.0μm, although photon flux remains significant as far as 6.0μm, compared to shorter wavelength fluxes.  UV-C radiation spans from 0.1μm to .28μm, UV-B from 0.28μm to 0.315μm, UV-A from 0.315μm to 0.4μm, the visible spectrum from 0.4μm to 0.7μm, and NIR arguably from 0.7μm to 5.0μm, beyond which the infrared is thermal.\n\nShortwave radiation is distinguished from longwave radiation. Downward shortwave radiation is sensitive to solar zenith angle, cloud cover.\nSI unitsThe  International System of Units (SI, abbreviated from the French Système international (d'unités)) is the modern form of the metric system. It is the only system of measurement with an official status in nearly every country in the world. It comprises a coherent system of units of measurement starting with seven base units, which are the second (the unit of time with the symbol s), metre (length, m), kilogram (mass, kg), ampere (electric current, A), kelvin (thermodynamic temperature, K), mole (amount of substance, mol), and candela (luminous intensity, cd). The system allows for an unlimited number of additional units, called derived units, which can always be represented as products of powers of the base units. Twenty-two derived units have been provided with special names and symbols. The seven base units and the 22 derived units with special names and symbols may be used in combination to express other derived units, which are adopted to facilitate measurement of diverse quantities. The SI also provides twenty prefixes to the unit names and unit symbols that may be used when specifying power-of-ten (i.e. decimal) multiples and sub-multiples of SI units. The SI is intended to be an evolving system; units and prefixes are created and unit definitions are modified through international agreement as the technology of measurement progresses and the precision of measurements improves. \nSignal processingIs an electrical engineering subfield that focuses on analysing, modifying, and synthesizing signals such as sound, images, and scientific measurements. Signal processing techniques can be used to improve transmission, storage efficiency and subjective quality and to also emphasize or detect components of interest in a measured signal.\nSimple machineis a mechanical device that changes the direction or magnitude of a force. In general, they can be defined as the simplest mechanisms that use mechanical advantage (also called leverage) to multiply force. Usually the term refers to the six classical simple machines that were defined by Renaissance scientists:\nLever\nWheel and axle\nPulley\nInclined plane\nWedge\nScrew\nSiphonA closed tube that conveys liquids between two levels without pumping.\nSolid mechanicsalso known as mechanics of solids, is the branch of continuum mechanics that studies the behavior of solid materials, especially their motion and deformation under the action of forces, temperature changes, phase changes, and other external or internal agents.\nSolid-state physicsis the study of rigid matter, or solids, through methods such as quantum mechanics, crystallography, electromagnetism, and metallurgy.  It is the largest branch of condensed matter physics. Solid-state physics studies how the large-scale properties of solid materials result from their atomic-scale properties.   Thus,  solid-state physics forms a theoretical basis of materials science.  It also has direct applications, for example in the technology of transistors and semiconductors.\nSolid solution strengtheningis a type of alloying that can be used to improve the strength of a pure metal. The technique works by adding atoms of one element (the alloying element) to the crystalline lattice of another element (the base metal), forming a solid solution. The local nonuniformity in the lattice due to the alloying element makes plastic deformation more difficult by impeding dislocation motion through stress fields. In contrast, alloying beyond the solubility limit can form a second phase, leading to strengthening via other mechanisms (e.g. the precipitation of intermetallic compounds).\nSolubilityis the property of a solid, liquid or gaseous chemical substance called solute to dissolve in a solid, liquid or gaseous solvent. The solubility of a substance fundamentally depends on the physical and chemical properties of the solute and solvent as well as on temperature, pressure and presence of other chemicals (including changes to the pH) of the solution. The extent of the solubility of a substance in a specific solvent is measured as the saturation concentration, where adding more solute does not increase the concentration of the solution and begins to precipitate the excess amount of solute.\nSolubility equilibriumis a type of dynamic equilibrium that exists when a chemical compound in the solid state is in chemical equilibrium with a solution of that compound. The solid may dissolve unchanged, with dissociation or with chemical reaction with another constituent of the solution, such as acid or alkali. Each solubility equilibrium is characterized by a temperature-dependent solubility product which functions like an  equilibrium constant. Solubility equilibria are important in pharmaceutical, environmental and many other scenarios.\nSoundIn physics, sound is a vibration that propagates as an acoustic wave, through a transmission medium such as a gas, liquid or solid.\nSpecial relativityIn physics, the special theory of relativity, or special relativity for short, is a scientific theory regarding the relationship between space and time. In Albert Einstein's original treatment, the theory is based on two postulates:\nThe laws of physics are invariant (that is, identical) in all inertial frames of reference (that is, frames of reference with no acceleration).\nThe speed of light in vacuum is the same for all observers, regardless of the motion of the light source or observer.\nSpecific heatThe amount of energy required to change the temperature of a unit mass of substance by one degree.\nSpecific gravityThe ratio between the mass density of a substance to that of water. \nSpecific volumeThe volume of a unit mass of a substance.\nSpecific weightThe weight of a substance per unit volume. \nSpontaneous combustionSpontaneous combustion or spontaneous ignition is a type of combustion which occurs by self-heating (increase in temperature due to exothermic internal reactions), followed by thermal runaway (self heating which rapidly accelerates to high temperatures) and finally, autoignition.\nStagnation pressureIn fluid dynamics, stagnation pressure (or pitot pressure) is the static pressure at a stagnation point in a fluid flow. At a stagnation point the fluid velocity is zero. In an incompressible flow, stagnation pressure is equal to the sum of the free-stream static pressure and the free-stream dynamic pressure.\nStandard electrode potential.\nState of matterIn physics, a state of matter is one of the distinct forms in which matter can exist. Four states of matter are observable in everyday life: solid, liquid, gas, and plasma. Many intermediate states are known to exist, such as liquid crystal, and some states only exist under extreme conditions, such as Bose–Einstein condensates, neutron-degenerate matter, and quark–gluon plasma, which only occur, respectively, in situations of extreme cold, extreme density, and extremely high energy. For a complete list of all exotic states of matter, see the list of states of matter.\nStaticsThe study of forces in a non-moving, rigid body. \nStatisticsis the discipline that concerns the collection, organization, analysis, interpretation, and presentation of data. In applying statistics to a scientific, industrial, or social problem, it is conventional to begin with a statistical population or a statistical model to be studied. Populations can be diverse groups of people or objects such as \"all people living in a country\" or \"every atom composing a crystal\". Statistics deals with every aspect of data, including the planning of data collection in terms of the design of surveys and experiments.\nSteam tableThermodynamic data table containing steam or water properties .\nStefan–Boltzmann lawThe Stefan–Boltzmann law describes the power radiated from a black body in terms of its temperature.  Specifically, the Stefan–Boltzmann law states that the total energy radiated per unit surface area of a black body across all wavelengths per unit time \n  \n    \n      \n        \n          j\n          \n            ⋆\n          \n        \n      \n    \n    {\\displaystyle j^{\\star }}\n  \n (also known as the black-body radiant emittance) is directly proportional to the fourth power of the black body's thermodynamic temperature T:\n\n  \n    \n      \n        \n          j\n          \n            ⋆\n          \n        \n        =\n        σ\n        \n          T\n          \n            4\n          \n        \n        .\n      \n    \n    {\\displaystyle j^{\\star }=\\sigma T^{4}.}\n  \n\nThe constant of proportionality σ, called the Stefan–Boltzmann constant, is derived from other known physical constants. Since 2019, the value of the constant is\n\n  \n    \n      \n        σ\n        =\n        \n          \n            \n              2\n              \n                π\n                \n                  5\n                \n              \n              \n                k\n                \n                  4\n                \n              \n            \n            \n              15\n              \n                c\n                \n                  2\n                \n              \n              \n                h\n                \n                  3\n                \n              \n            \n          \n        \n        =\n        5.670374\n        …\n        ×\n        \n          10\n          \n            −\n            8\n          \n        \n        \n        \n          W\n          \n          \n            m\n            \n              −\n              2\n            \n          \n          \n          \n            K\n            \n              −\n              4\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\sigma ={\\frac {2\\pi ^{5}k^{4}}{15c^{2}h^{3}}}=5.670374\\ldots \\times 10^{-8}\\,\\mathrm {W\\,m^{-2}\\,K^{-4}} ,}\n  \n\nwhere k is the Boltzmann constant, h is the Planck constant, and c is the speed of light in vacuum. The radiance from a specified angle of view (watts per square metre per steradian) is given by\n\n  \n    \n      \n        L\n        =\n        \n          \n            \n              j\n              \n                ⋆\n              \n            \n            π\n          \n        \n        =\n        \n          \n            σ\n            π\n          \n        \n        \n          T\n          \n            4\n          \n        \n        .\n      \n    \n    {\\displaystyle L={\\frac {j^{\\star }}{\\pi }}={\\frac {\\sigma }{\\pi }}T^{4}.}\n  \n\nA body that does not absorb all incident radiation (sometimes known as a grey body) emits less total energy than a black body and is characterized by an emissivity, \n  \n    \n      \n        ε\n        <\n        1\n      \n    \n    {\\displaystyle \\varepsilon <1}\n  \n:\n\n  \n    \n      \n        \n          j\n          \n            ⋆\n          \n        \n        =\n        ε\n        σ\n        \n          T\n          \n            4\n          \n        \n        .\n      \n    \n    {\\displaystyle j^{\\star }=\\varepsilon \\sigma T^{4}.}\n  \n\nThe radiant emittance \n  \n    \n      \n        \n          j\n          \n            ⋆\n          \n        \n      \n    \n    {\\displaystyle j^{\\star }}\n  \n has dimensions of energy flux (energy per unit time per unit area), and the SI units of measure are joules per second per square metre, or equivalently, watts per square metre. The SI unit for absolute temperature T is the kelvin.  \n  \n    \n      \n        ε\n      \n    \n    {\\displaystyle \\varepsilon }\n  \n is the emissivity of the grey body; if it is a perfect blackbody, \n  \n    \n      \n        ε\n        =\n        1\n      \n    \n    {\\displaystyle \\varepsilon =1}\n  \n. In the still more general (and realistic) case, the emissivity depends on the wavelength, \n  \n    \n      \n        ε\n        =\n        ε\n        (\n        λ\n        )\n      \n    \n    {\\displaystyle \\varepsilon =\\varepsilon (\\lambda )}\n  \n.\n\nTo find the total power radiated from an object, multiply by its surface area, \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n:\n\n  \n    \n      \n        P\n        =\n        A\n        \n          j\n          \n            ⋆\n          \n        \n        =\n        A\n        ε\n        σ\n        \n          T\n          \n            4\n          \n        \n        .\n      \n    \n    {\\displaystyle P=Aj^{\\star }=A\\varepsilon \\sigma T^{4}.}\n  \n\nWavelength- and subwavelength-scale particles, metamaterials, and other nanostructures are not subject to ray-optical limits and may be designed to exceed the Stefan–Boltzmann law.\nStewart platformis a type of parallel manipulator that has six prismatic actuators, commonly hydraulic jacks or electric linear actuators, attached in pairs to three positions on the platform's baseplate, crossing over to three mounting points on a top plate. All 12 connections are made via universal joints. Devices placed on the top plate can be moved in the six degrees of freedom in which it is possible for a freely-suspended body to move: three linear movements x, y, z (lateral, longitudinal, and vertical), and the three rotations (pitch, roll, and yaw). \nStiffnessis the extent to which an object resists deformation in response to an applied force.\n\nThe complementary concept is flexibility or pliability: the more flexible an object is, the less stiff it is.\nStoichiometryrefers to the relationship between the quantities of reactants and products before, during, and following chemical reactions.\n\nStoichiometry is founded on the law of conservation of mass where the total mass of the reactants equals the total mass of the products, leading to the insight that the relations among quantities of reactants and products typically form a ratio of positive integers.   This means that if the amounts of the separate reactants are known, then the amount of the product can be calculated. Conversely, if one reactant has a known quantity and the quantity of the products can be empirically determined, then the amount of the other reactants can also be calculated.\nStrain.\nStrain hardeningWork hardening, also known as strain hardening, is the strengthening of a metal or polymer by plastic deformation. Work hardening may be desirable, undesirable, or inconsequential, depending on the context.\n\nThis strengthening occurs because of dislocation movements and dislocation generation within the crystal structure of the material. Many non-brittle metals with a reasonably high melting point as well as several polymers can be strengthened in this fashion. Alloys not amenable to heat treatment, including low-carbon steel, are often work-hardened. Some materials cannot be work-hardened at low temperatures, such as indium, however others can be strengthened only via work hardening, such as pure copper and aluminum.\nStrength of materialsThe field of strength of materials, also called mechanics of materials, typically refers to various methods of calculating the stresses and strains in structural members, such as beams, columns, and shafts. The methods employed to predict the response of a structure under loading and its susceptibility to various failure modes takes into account the properties of the materials such as its yield strength, ultimate strength, Young's modulus, and Poisson's ratio. In addition, the mechanical element's macroscopic properties (geometric properties) such as its length, width, thickness, boundary constraints and abrupt changes in geometry such as holes are considered.\nStressIn continuum mechanics, stress is a physical quantity that expresses the internal forces that neighbouring particles of a continuous material exert on each other, while strain is the measure of the deformation of the material. For example, when a solid vertical bar is supporting an overhead weight, each particle in the bar pushes on the particles immediately below it. When a liquid is in a closed container under pressure, each particle gets pushed against by all the surrounding particles.  The container walls and the pressure-inducing surface (such as a piston) push against them in (Newtonian) reaction. These macroscopic forces are actually the net result of a very large number of intermolecular forces and collisions between the particles in those molecules. Stress is frequently represented by a lowercase Greek letter sigma (σ).\nStress–strain analysisStress–strain analysis (or stress analysis) is an engineering discipline that uses many methods to determine the stresses and strains in materials and structures subjected to forces. In continuum mechanics, stress is a physical quantity that expresses the internal forces that neighboring particles of a continuous material exert on each other, while strain is the measure of the deformation of the material.\n\nIn simple terms we can define stress as the force of resistance per unit per unit area, offered by a body against deformation. Stress is the ratio of force over area (S =R/A, where S is the stress, R is the internal resisting force and A is the cross-sectional area). Strain is the ratio of change in length to the original length, when a given body is subjected to some external force (Strain= change in length÷the original length).\nStress–strain curveIn engineering and materials science, a stress–strain curve for a material gives the relationship between stress and strain. It is obtained by gradually applying load to a test coupon and measuring the deformation, from which the stress and strain can be determined (see tensile testing). These curves reveal many of the properties of a material, such as the Young's modulus, the yield strength and the ultimate tensile strength.\nStructural analysisis the determination of the effects of loads on physical structures and their components.\nStructures subject to this type of analysis include all that must withstand loads, such as buildings, bridges, aircraft and ships.  Structural analysis employs the fields of applied mechanics, materials science and applied mathematics to compute a structure's deformations, internal forces, stresses, support reactions, accelerations, and stability. The results of the analysis are used to verify a structure's fitness for use, often precluding physical tests. Structural analysis is thus a key part of the engineering design of structures. \nStructural loadA structural load or structural action is a force, deformation, or acceleration applied to structural elements. A load causes stress, deformation, and displacement in a structure. Structural analysis, a discipline in engineering, analyzes the effects loads on structures and structural elements. Excess load may cause structural failure, so this should be considered and controlled during the design of a structure. Particular  mechanical structures—such as aircraft, satellites, rockets, space stations, ships, and submarines—are subject to their own particular structural loads and actions. Engineers often evaluate structural loads based upon published regulations, contracts, or specifications.  Accepted technical standards are used for acceptance testing and inspection.\nSublimationis the transition of a substance directly from the solid to the gas state, without passing through the liquid state. Sublimation is an endothermic process that occurs at temperatures and pressures below a substance's triple point in its phase diagram, which corresponds to the lowest pressure at which the substance can exist as a liquid. The reverse process of sublimation is deposition or desublimation, in which a substance passes directly from a gas to a solid phase. Sublimation has also been used as a generic term to describe a solid-to-gas transition (sublimation) followed by a gas-to-solid transition (deposition). While vaporization from liquid to gas occurs as evaporation from the surface if it occurs below the boiling point of the liquid, and as boiling with formation of bubbles in the interior of the liquid if it occurs at the boiling point, there is no such distinction for the solid-to-gas transition which always occurs as sublimation from the surface.\nSubsumption architectureis a reactive robotic architecture heavily associated with behavior-based robotics which was very popular in the 1980s and 90s.  The term was introduced by Rodney Brooks and colleagues in 1986.  Subsumption has been widely influential in autonomous robotics and elsewhere in real-time AI. \nSurface tensionis the tendency of liquid surfaces at rest to shrink into the minimum surface area possible. Surface tension is what allows objects with a higher density than water to float on a water surface without becoming even partly submerged.\nSuperconductivityis a set of physical properties observed in certain materials where electrical resistance vanishes and magnetic flux fields are expelled from the material. Any material exhibiting these properties is a superconductor. Unlike an ordinary metallic conductor, whose resistance decreases gradually as its temperature is lowered even down to near absolute zero, a superconductor has a characteristic critical temperature below which the resistance drops abruptly to zero. An electric current through a loop of superconducting wire can persist indefinitely with no power source.\nSuperhard materialis a material with a hardness value exceeding 40 gigapascals (GPa) when measured by the Vickers hardness test. They are virtually incompressible solids with high electron density and high bond covalency. As a result of their unique properties, these materials are of great interest in many industrial areas including, but not limited to, abrasives, polishing and cutting tools, disc brakes, and wear-resistant and protective coatings.\nSupersaturationSupersaturation occurs with a chemical solution when the concentration of a solute exceeds the concentration specified by the value equilibrium solubility. Most commonly the term is applied to a solution of a solid in a liquid. A supersaturated solution is in a metastable state; it may be brought to equilibrium by forcing the excess of solute to separate from the solution. The term can also  be applied to a mixture of gases.\n\n\n== T ==\n\nTangential accelerationThe velocity of a particle moving on a curved path as a function of time can be written as:\n\n  \n    \n      \n        \n          v\n        \n        (\n        t\n        )\n        =\n        v\n        (\n        t\n        )\n        \n          \n            \n              \n                v\n              \n              (\n              t\n              )\n            \n            \n              v\n              (\n              t\n              )\n            \n          \n        \n        =\n        v\n        (\n        t\n        )\n        \n          \n            u\n          \n          \n            \n              t\n            \n          \n        \n        (\n        t\n        )\n        ,\n      \n    \n    {\\displaystyle \\mathbf {v} (t)=v(t){\\frac {\\mathbf {v} (t)}{v(t)}}=v(t)\\mathbf {u} _{\\mathrm {t} }(t),}\n  \n\nwith v(t) equal to the speed of travel along the path, and\n\n  \n    \n      \n        \n          \n            u\n          \n          \n            \n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                v\n              \n              (\n              t\n              )\n            \n            \n              v\n              (\n              t\n              )\n            \n          \n        \n         \n        ,\n      \n    \n    {\\displaystyle \\mathbf {u} _{\\mathrm {t} }={\\frac {\\mathbf {v} (t)}{v(t)}}\\ ,}\n  \n\na unit vector tangent to the path pointing in the direction of motion at the chosen moment in time. Taking into account both the changing speed v(t) and the changing direction of ut, the acceleration of a particle moving on a curved path can be written using the chain rule of differentiation for the product of two functions of time as:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  a\n                \n              \n              \n                \n                =\n                \n                  \n                    \n                      d\n                      \n                        v\n                      \n                    \n                    \n                      d\n                      t\n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \n                    \n                      d\n                      v\n                    \n                    \n                      d\n                      t\n                    \n                  \n                \n                \n                  \n                    u\n                  \n                  \n                    \n                      t\n                    \n                  \n                \n                +\n                v\n                (\n                t\n                )\n                \n                  \n                    \n                      d\n                      \n                        \n                          u\n                        \n                        \n                          \n                            t\n                          \n                        \n                      \n                    \n                    \n                      d\n                      t\n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \n                    \n                      d\n                      v\n                    \n                    \n                      d\n                      t\n                    \n                  \n                \n                \n                  \n                    u\n                  \n                  \n                    \n                      t\n                    \n                  \n                \n                +\n                \n                  \n                    \n                      v\n                      \n                        2\n                      \n                    \n                    r\n                  \n                \n                \n                  \n                    u\n                  \n                  \n                    \n                      n\n                    \n                  \n                \n                 \n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{alignedat}{3}\\mathbf {a} &={\\frac {d\\mathbf {v} }{dt}}\\\\&={\\frac {dv}{dt}}\\mathbf {u} _{\\mathrm {t} }+v(t){\\frac {d\\mathbf {u} _{\\mathrm {t} }}{dt}}\\\\&={\\frac {dv}{dt}}\\mathbf {u} _{\\mathrm {t} }+{\\frac {v^{2}}{r}}\\mathbf {u} _{\\mathrm {n} }\\ ,\\end{alignedat}}}\n  \n\nwhere un is the  unit (inward) normal vector to the particle's trajectory (also called the principal normal), and r is its instantaneous radius of curvature based upon the osculating circle at time t. These components are called the tangential acceleration and the normal or radial acceleration (or centripetal acceleration in circular motion, see also circular motion and centripetal force).\n\nGeometrical analysis of three-dimensional space curves, which explains tangent, (principal) normal and binormal, is described by the Frenet–Serret formulas.\nTechnical standardA technical standard is an established norm or requirement for a repeatable technical task. It is usually a formal document that establishes uniform engineering or technical criteria, methods, processes, and practices. In contrast, a custom, convention, company product, corporate standard, and so forth that becomes generally accepted and dominant is often called a de facto standard.\nTemperatureis a physical quantity that expresses hot and cold. It is the manifestation of thermal energy, present in all matter, which is the source of the occurrence of heat, a flow of energy, when a body is in contact with another that is colder. Temperature is measured with a thermometer. Thermometers are calibrated in various temperature scales that historically have used various reference points and thermometric substances for definition. The most common scales are the Celsius scale (formerly called centigrade, denoted °C), the Fahrenheit scale (denoted °F), and the Kelvin scale (denoted K), the last of which is predominantly used for scientific purposes by conventions of the International System of Units (SI). \nTempering (metallurgy)Heat treatment to alter the crystal structure of a metal such as steel.\nTensile forcePulling force, tending to lengthen an object.\nTensile modulusYoung's modulus \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  \n, the Young modulus, or the modulus of elasticity in tension, is a mechanical property that measures the tensile stiffness of a solid material. It quantifies the relationship between tensile stress \n  \n    \n      \n        σ\n      \n    \n    {\\displaystyle \\sigma }\n  \n (force per unit area) and axial strain \n  \n    \n      \n        ε\n      \n    \n    {\\displaystyle \\varepsilon }\n  \n (proportional deformation) in the linear elastic region of a material and is determined using the formula:\n\n  \n    \n      \n        E\n        =\n        \n          \n            σ\n            ε\n          \n        \n      \n    \n    {\\displaystyle E={\\frac {\\sigma }{\\varepsilon }}}\n  \n\nYoung's moduli are typically so large that they are expressed not in pascals but in gigapascals (GPa).\nTensile strengthUltimate tensile strength (UTS), often shortened to tensile strength (TS), ultimate strength, or \n  \n    \n      \n        \n          F\n          \n            tu\n          \n        \n      \n    \n    {\\displaystyle F_{\\text{tu}}}\n  \n within equations, is the maximum stress that a material can withstand while being stretched or pulled before breaking. In brittle materials the ultimate tensile strength is close to the yield point, whereas in ductile materials the ultimate tensile strength can be higher.\nTensile testingTensile testing, also known as tension testing, is a fundamental materials science and engineering test in which a sample is subjected to a controlled tension until failure. Properties that are directly measured via a tensile test are ultimate tensile strength, breaking strength, maximum elongation and reduction in area. From these measurements the following properties can also be determined: Young's modulus, Poisson's ratio, yield strength, and strain-hardening characteristics. Uniaxial tensile testing is the most commonly used for obtaining the mechanical characteristics of isotropic materials. Some materials use biaxial tensile testing. The main difference between these testing machines being how load is applied on the materials.\nTension memberTension members are structural elements that are subjected to axial tensile forces. Examples of tension members are bracing for buildings and bridges, truss members, and cables in suspended roof systems.\nThermal conductionis the transfer of internal energy by microscopic collisions of particles and movement of electrons within a body. The colliding particles, which include molecules, atoms and electrons, transfer disorganized microscopic kinetic and potential energy, jointly known as internal energy. Conduction takes place in all phases: solid, liquid, and gas.\nThermal equilibriumTwo physical systems are in thermal equilibrium if there is no net flow of thermal energy between them when they are connected by a path permeable to heat.  Thermal equilibrium obeys the zeroth law of thermodynamics.  A system is said to be in thermal equilibrium with itself if the temperature within the system is spatially uniform and temporally constant.\n\nSystems in thermodynamic equilibrium are always in thermal equilibrium, but the converse is not always true.  If the connection between the systems allows transfer of energy as 'change in internal energy' but does not allow transfer of matter or transfer of energy as work, the two systems may reach thermal equilibrium without reaching thermodynamic equilibrium.\nThermal radiationis electromagnetic radiation generated by the thermal motion of particles in matter. All matter with a temperature greater than absolute zero emits thermal radiation. Particle motion results in charge-acceleration or dipole oscillation which produces electromagnetic radiation.\nThermodynamicsis a branch of physics that deals with heat, work, and temperature, and their relation to energy, radiation, and physical properties of matter. The behavior of these quantities is governed by the four laws of thermodynamics which convey a quantitative description using measurable macroscopic physical quantities, but may be explained in terms of microscopic constituents by statistical mechanics. Thermodynamics applies to a wide variety of topics in science and engineering, especially physical chemistry, biochemistry, chemical engineering and mechanical engineering, but also in other complex fields such as meteorology.\nTheory of relativityusually encompasses two interrelated theories by Albert Einstein: special relativity and general relativity, proposed and published in 1905 and 1915, respectively. Special relativity applies to all physical phenomena in the absence of gravity. General relativity explains the law of gravitation and its relation to other forces of nature. It applies to the cosmological and astrophysical realm, including astronomy.\nThévenin's theoremAs originally stated in terms of direct-current resistive circuits only, Thévenin's theorem states that \"For any linear electrical network containing only voltage sources, current sources and resistances can be replaced at terminals A–B by an equivalent combination of a voltage source Vth in a series connection with a resistance Rth.\"\nThe equivalent voltage Vth is the voltage obtained at terminals A–B of the network with terminals A–B open circuited.\nThe equivalent resistance Rth is the resistance that the circuit between terminals A and B would have if all ideal voltage sources in the circuit were replaced by a short circuit and all ideal current sources were replaced by an open circuit.\nIf terminals A and B are connected to one another, the current flowing from A to B will be Vth/Rth. This means that Rth could alternatively be calculated as Vth divided by the short-circuit current between A and B when they are connected together.\n\nIn circuit theory terms, the theorem allows any one-port network to be reduced to a single voltage source and a single impedance.\n\nThe theorem also applies to frequency domain AC circuits consisting of reactive and resistive impedances. It means the theorem applies for AC in an exactly same way to DC except that resistances are generalized to impedances.\nThree-phase electric poweris a common method of alternating current electric power generation, transmission, and distribution. It is a type of polyphase system and is the most common method used by electrical grids worldwide to transfer power. It is also used to power large motors and other heavy loads.\nTorqueIn physics and mechanics, torque is the rotational equivalent of linear force. It is also referred to as the moment, moment of force, rotational force or turning effect, depending on the field of study.  The concept originated with the studies by Archimedes of the usage of levers. Just as a linear force is a push or a pull, a torque can be thought of as a twist to an object around a specific axis. Another definition of torque is the product of the magnitude of the force and the perpendicular distance of the line of action of a force from the axis of rotation. The symbol for torque is typically \n  \n    \n      \n        \n          τ\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}}\n  \n or τ, the lowercase Greek letter tau. When being referred to as moment of force, it is commonly denoted by M.\nTorsional vibrationis angular vibration of an object—commonly a shaft along its axis of rotation.  Torsional vibration is often a concern in power transmission systems using rotating shafts or couplings where it can cause failures if not controlled. A second effect of torsional vibrations applies to passenger cars. Torsional vibrations can lead to seat vibrations or noise at certain speeds. Both reduce the comfort.\nToughnessIn materials science and metallurgy, toughness is the ability of a material to absorb energy and plastically deform without fracturing. One definition of material toughness is the amount of energy per unit volume that a material can absorb before rupturing. This measure of toughness is different from that used for fracture toughness, which describes load bearing capabilities of materials with flaws. It is also defined as a material's resistance to fracture when stressed.\n\nToughness requires a balance of strength and ductility.\nTrajectoryA trajectory or flight path is the path that an object with mass in motion follows through space as a function of time. In classical mechanics, a trajectory is defined by Hamiltonian mechanics via canonical coordinates; hence, a complete trajectory is defined by position and momentum, simultaneously.\n\nThe mass might be a projectile or a satellite. For example, it can be an orbit — the path of a planet, asteroid, or comet as it travels around a central mass.\n\nIn control theory, a trajectory is a time-ordered set of states of a dynamical system (see e.g. Poincaré map). In discrete mathematics, a trajectory is a sequence \n  \n    \n      \n        (\n        \n          f\n          \n            k\n          \n        \n        (\n        x\n        )\n        \n          )\n          \n            k\n            ∈\n            \n              N\n            \n          \n        \n      \n    \n    {\\displaystyle (f^{k}(x))_{k\\in \\mathbb {N} }}\n  \n of values calculated by the iterated application of a mapping \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n to an element \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n of its source.\nTransduceris a device that converts energy from one form to another. Usually a transducer converts a signal in one form of energy to a signal in another.\n\nTransducers are often employed at the boundaries of automation, measurement, and control systems, where electrical signals are converted to and from other physical quantities (energy, force, torque, light, motion, position, etc.). The process of converting one form of energy to another is known as transduction.\nTransformeris a passive component that transfers electrical energy from one electrical circuit to another circuit, or multiple circuits. A varying current in any one coil of the transformer produces a varying magnetic flux in the transformer's core, which induces a varying electromotive force across any other coils wound around the same core. Electrical energy can be transferred between separate coils without a metallic (conductive) connection between the two circuits. Faraday's law of induction, discovered in 1831, describes the induced voltage effect in any coil due to a changing magnetic flux encircled by the coil.\nTrigonometric functionsIn mathematics, the trigonometric functions (also called circular functions, angle functions or goniometric functions) are real functions which relate an angle of a right-angled triangle to ratios of two side lengths. They are widely used in all sciences that are related to geometry, such as navigation, solid mechanics, celestial mechanics, geodesy, and many others. They are among the simplest periodic functions, and as such are also widely used for studying periodic phenomena through Fourier analysis.\n\nThe trigonometric functions most widely used in modern mathematics are the sine, the cosine, and the tangent. Their reciprocals are respectively the cosecant, the secant, and the cotangent, which are less used. Each of these six trigonometric functions has a corresponding inverse function, and an analog among the hyperbolic functions.\nTrigonometryIs a branch of mathematics that studies relationships between side lengths and angles of triangles. The field emerged in the Hellenistic world during the 3rd century BC from applications of geometry to astronomical studies. The Greeks focused on the calculation of chords, while mathematicians in India created the earliest-known tables of values for  trigonometric ratios (also called trigonometric functions) such as sine.\nTrimeanThe trimean is a measure of a probability distribution's location defined as a weighted average of the distribution's median and its two quartiles\nTriple pointIn thermodynamics, the triple point of a substance is the temperature and pressure at which the three phases (gas, liquid, and solid) of that substance coexist in thermodynamic equilibrium. It is that temperature and pressure at which the sublimation curve, fusion curve and the vaporisation curve meet. For example, the triple point of mercury occurs at a temperature of −38.83440 °C (−37.90192 °F) and a pressure of 0.165 mPa.  In addition to the triple point for solid, liquid, and gas phases, a triple point may involve more than one solid phase, for substances with multiple polymorphs. Helium-4 is a special case that presents a triple point involving two different fluid phases (lambda point).\nTrouton's ruleTrouton's rule states that the entropy of vaporization  is almost the same value, about 85–88 J/(K·mol), for various kinds of liquids at their boiling points. The entropy of vaporization is defined as the ratio between the enthalpy of vaporization and the boiling temperature. It is named after Frederick Thomas Trouton.\n\nIt can be expressed as a function of the gas constant R:\n\n  \n    \n      \n        Δ\n        \n          \n            \n              \n                S\n                ¯\n              \n            \n          \n          \n            vap\n          \n        \n        ≈\n        10.5\n        R\n        .\n      \n    \n    {\\displaystyle \\Delta {\\bar {S}}_{\\text{vap}}\\approx 10.5R.}\n  \n\nA similar way of stating this (Trouton's ratio) is that the latent heat is connected to boiling point roughly as\n\n  \n    \n      \n        \n          \n            \n              L\n              \n                vap\n              \n            \n            \n              T\n              \n                boiling\n              \n            \n          \n        \n        ≈\n        85\n        \n          −\n        \n        88\n         \n        \n          \n            J\n            \n              \n                K\n              \n              ⋅\n              \n                mol\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {L_{\\text{vap}}}{T_{\\text{boiling}}}}\\approx 85{-}88\\ {\\frac {\\text{J}}{{\\text{K}}\\cdot {\\text{mol}}}}.}\n  \n\nTruncated meanA truncated mean or trimmed mean is a statistical measure of central tendency, much like the mean and median. It involves the calculation of the mean after discarding given parts of a probability distribution or sample at the high and low end, and typically discarding an equal amount of both. This number of points to be discarded is usually given as a percentage of the total number of points, but may also be given as a fixed number of points.\nTrussA truss is an assembly of members such as beams, connected by nodes, that creates a rigid structure.\n\nIn engineering, a truss is a structure that \"consists of two-force members only, where the members are organized so that the assemblage as a whole behaves as a single object\".  A \"two-force member\" is a structural component where force is applied to only two points.  Although this rigorous definition allows the members to have any shape connected in any stable configuration, trusses typically comprise five or more triangular units constructed with straight members whose ends are connected at joints referred to as nodes.\nTurbineis a rotary mechanical device that extracts energy from a fluid flow and converts it into useful work. The work produced by a turbine can be used for generating electrical power when combined with a generator. A turbine is a turbomachine with at least one moving part called a rotor assembly, which is a shaft or drum with blades attached. Moving fluid acts on the blades so that they move and impart rotational energy to the rotor. Early turbine examples are windmills and waterwheels. Gas, steam, and water turbines have a casing around the blades that contains and controls the working fluid.\n TurbomachineryTurbomachinery, in mechanical engineering, describes machines that transfer energy between a rotor and a fluid, including both turbines and compressors.  While a turbine transfers energy from a fluid to a rotor, a compressor transfers energy from a rotor to a fluid.\nTurbulenceIn fluid dynamics, turbulence or turbulent flow is fluid motion characterized by chaotic changes in pressure and flow velocity.  It is in contrast to a laminar flow, which occurs when a fluid flows in parallel layers, with no disruption between those layers.\n\n\n== U ==\n\nUltimate tensile strengthUltimate tensile strength (UTS), often shortened to tensile strength (TS), ultimate strength, or Ftu within equations, is the capacity of a material or structure to withstand loads tending to elongate, as opposed to compressive strength, which withstands loads tending to reduce size. In other words, tensile strength resists tension (being pulled apart), whereas compressive strength resists compression (being pushed together). Ultimate tensile strength is measured by the maximum stress that a material can withstand while being stretched or pulled before breaking. In the study of strength of materials, tensile strength, compressive strength, and shear strength can be analyzed independently.\nUncertainty principleIn quantum mechanics, the uncertainty principle (also known as Heisenberg's uncertainty principle) is any of a variety of mathematical inequalities asserting a fundamental limit to the precision with which certain pairs of physical properties of a particle, known as complementary variables, such as position x and momentum p, can be known.\nUnicodeA standard for the consistent encoding of textual characters.\nUnit vectorIn mathematics, a unit vector in a normed vector space is a vector (often a spatial vector) of length 1. A unit vector is often denoted by a lowercase letter with a circumflex, or \"hat\": \n  \n    \n      \n        \n          \n            \n              ı\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {\\imath }}}\n  \n (pronounced \"i-hat\"). The term direction vector is used to describe a unit vector being used to represent spatial direction, and such quantities are commonly denoted as d. .\nUnsaturated compound.\nUpthrustBuoyancy, or upthrust, is an upward force exerted by a fluid that opposes the weight of a partially or fully immersed object. In a column of fluid, pressure increases with depth as a result of the weight of the overlying fluid. Thus the pressure at the bottom of a column of fluid is greater than at the top of the column. Similarly, the pressure at the bottom of an object submerged in a fluid is greater than at the top of the object. The pressure difference results in a net upward force on the object. The magnitude of the force is proportional to the pressure difference, and (as explained by Archimedes' principle) is equivalent to the weight of the fluid that would otherwise occupy the submerged volume of the object, i.e. the displaced fluid.\nUtility frequencyThe utility frequency, (power) line frequency (American English) or mains frequency (British English) is the nominal frequency of the oscillations of alternating current (AC) in a wide area synchronous grid transmitted from a power station to the end-user. In large parts of the world this is 50 Hz, although in the Americas and parts of Asia it is typically 60 Hz. Current usage by country or region is given in the list of mains electricity by country.\n\n\n== V ==\n\nVacuoleis a membrane-bound organelle which is present in plant and fungal cells and some protist, animal and bacterial cells. Vacuoles are essentially enclosed compartments which are filled with water containing inorganic and organic molecules including enzymes in solution, though in certain cases they may contain solids which have been engulfed. Vacuoles are formed by the fusion of multiple membrane vesicles and are effectively just larger forms of these. The organelle has no basic shape or size; its structure varies according to the requirements of the cell.\nVacuumAn absence of mass in a volume.\nValenceIn chemistry, the valence or valency of an element is a measure of its combining power with other atoms when it forms chemical compounds or molecules. The concept of  valence developed in the second half of the 19th century and helped successfully explain the molecular structure of inorganic and organic compounds. \nThe quest for the underlying causes of valence led to the modern theories of chemical bonding, including the cubical atom (1902), Lewis structures (1916), valence bond theory (1927), molecular orbitals (1928), valence shell electron pair repulsion theory (1958), and all of the advanced methods of quantum chemistry. \nValence bandIn solid-state physics, the valence band and conduction band are the bands closest to the Fermi level and thus determine the electrical conductivity of the solid. In non-metals, the valence band is the highest range of electron energies in which electrons are normally present at absolute zero temperature, while the conduction band is the lowest range of vacant electronic states. On a graph of the electronic band structure of a material, the valence band is located below the Fermi level, while the conduction band is located above it. The distinction between the valence and conduction bands is meaningless in metals, because conduction occurs in one or more partially filled bands that take on the properties of both the valence and conduction bands. \nValence bond theoryIn chemistry, valence bond (VB) theory is one of the two basic theories, along with molecular orbital (MO) theory, that were developed to use the methods of quantum mechanics to explain chemical bonding. It focuses on how the atomic orbitals of the dissociated atoms combine to give individual chemical bonds when a molecule is formed. In contrast, molecular orbital theory has orbitals that cover the whole molecule.\nValence electronIn chemistry and physics, a valence electron is an outer shell electron that is associated with an atom, and that can participate in the formation of a chemical bond if the outer shell is not closed; in a single covalent bond, both atoms in the bond contribute one valence electron in order to form a shared pair. \nValence shellThe valence shell is the set of orbitals which are energetically accessible for accepting electrons to form chemical bonds. For main group elements, the valence shell consists of the ns and np orbitals in the outermost electron shell. In the case of transition metals (the (n-1)d orbitals), and lanthanides and actinides (the (n-2)f and (n-1)d orbitals), the orbitals involved can also be in an inner electron shell. Thus, the shell terminology is a misnomer as there is no correspondence between the valence shell and any particular electron shell in a given element. A scientifically correct term would be valence orbital to refer to the energetically accessible orbitals of an element. \nValveis a device or natural object that regulates, directs or controls the flow of a fluid (gases, liquids, fluidized solids, or slurries) by opening, closing, or partially obstructing various passageways. Valves are technically fittings, but are usually discussed as a separate category. In an open valve, fluid flows in a direction from higher pressure to lower pressure. The word is derived from the Latin valva, the moving part of a door, in turn from volvere, to turn, roll.  \nvan der Waals equationIn chemistry and thermodynamics, the Van der Waals equation (or Van der Waals equation of state; named after Dutch physicist Johannes Diderik van der Waals) is an equation of state that generalizes the ideal gas law based on plausible reasons that real gases do not act ideally. The ideal gas law treats gas molecules as point particles that interact with their containers but not each other, meaning they neither take up space nor change kinetic energy during collisions (i.e. all collisions are perfectly elastic). The ideal gas law states that volume (V) occupied by n moles of any gas has a pressure (P) at temperature (T) in kelvins given by the following relationship, where R is the gas constant:\n\n  \n    \n      \n        P\n        V\n        =\n        n\n        R\n        T\n      \n    \n    {\\displaystyle PV=nRT}\n  \n\nTo account for the volume that a real gas molecule takes up, the Van der Waals equation replaces V in the ideal gas law with \n  \n    \n      \n        (\n        \n          V\n          \n            m\n          \n        \n        −\n        b\n        )\n      \n    \n    {\\displaystyle (V_{m}-b)}\n  \n, where Vm is the molar volume of the gas and b is the volume that is occupied by one mole of the molecules. This leads to:\n\n  \n    \n      \n        P\n        (\n        \n          V\n          \n            m\n          \n        \n        −\n        b\n        )\n        =\n        R\n        T\n      \n    \n    {\\displaystyle P(V_{m}-b)=RT}\n  \n\nThe second modification made to the ideal gas law accounts for the fact that gas molecules do in fact interact with each other (they usually experience attraction at low pressures and repulsion at high pressures) and that real gases therefore show different compressibility than ideal gases. Van der Waals provided for intermolecular interaction by adding to the observed pressure P in the equation of state a term \n  \n    \n      \n        a\n        \n          /\n        \n        \n          V\n          \n            m\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle a/V_{m}^{2}}\n  \n, where a is a constant whose value depends on the gas. The Van der Waals equation is therefore written as:\n\n  \n    \n      \n        \n          (\n          \n            P\n            +\n            a\n            \n              \n                1\n                \n                  V\n                  \n                    m\n                  \n                  \n                    2\n                  \n                \n              \n            \n          \n          )\n        \n        (\n        \n          V\n          \n            m\n          \n        \n        −\n        b\n        )\n        =\n        R\n        T\n      \n    \n    {\\displaystyle \\left(P+a{\\frac {1}{V_{m}^{2}}}\\right)(V_{m}-b)=RT}\n  \n\nand, for n moles of gas, can also be written as the equation below:\n\n  \n    \n      \n        \n          (\n          \n            P\n            +\n            a\n            \n              \n                \n                  n\n                  \n                    2\n                  \n                \n                \n                  V\n                  \n                    2\n                  \n                \n              \n            \n          \n          )\n        \n        (\n        V\n        −\n        n\n        b\n        )\n        =\n        n\n        R\n        T\n      \n    \n    {\\displaystyle \\left(P+a{\\frac {n^{2}}{V^{2}}}\\right)(V-nb)=nRT}\n  \n\nwhere Vm is the molar volume of the gas, R is the universal gas constant, T is temperature, P is pressure, and V is volume. When the molar volume Vm is large, b becomes negligible in comparison with Vm, a/Vm2 becomes negligible with respect to P, and the Van der Waals equation reduces to the ideal gas law, PVm=RT.\n\nIt is available via its traditional derivation (a mechanical equation of state), or via a derivation based in statistical thermodynamics, the latter of which provides the partition function of the system and allows thermodynamic functions to be specified. It successfully approximates the behavior of real fluids above their critical temperatures and is qualitatively reasonable for their liquid and low-pressure gaseous states at low temperatures. However, near the phase transitions between gas and liquid, in the range of p, V, and T where the liquid phase and the gas phase are in equilibrium, the Van der Waals equation fails to accurately model observed experimental behaviour, in particular that p is a constant function of V at given temperatures. As such, the Van der Waals model is not useful only for calculations intended to predict real behavior in regions near the critical point. Corrections to address these predictive deficiencies have since been made, such as the equal area rule or the principle of corresponding states. \nvan der Waals forceIn molecular physics, the Van der Waals force, named after Dutch physicist Johannes Diderik van der Waals, is a distance-dependent interaction between atoms or molecules. Unlike ionic or covalent bonds, these attractions do not result from a chemical electronic bond; they are comparatively weak and therefore more susceptible to disturbance. The Van der Waals force quickly vanishes at longer distances between interacting molecules. \nvan 't Hoff equationrelates the change in the equilibrium constant, Keq, of a chemical reaction to the change in temperature, T, given the standard enthalpy change, ΔrH⊖, for the process. It was proposed by Dutch chemist Jacobus Henricus van 't Hoff in 1884 in his book Études de dynamique chimique (Studies in Dynamic Chemistry).\n\nThe Van 't Hoff equation has been widely utilized to explore the changes in state functions in a thermodynamic system. The Van 't Hoff plot, which is derived from this equation, is especially effective in estimating the change in enthalpy and entropy of a chemical reaction. \nvan 't Hoff factoris a measure of the effect of a solute on colligative properties such as osmotic pressure, relative lowering in vapor pressure, boiling-point elevation and freezing-point depression. The Van 't Hoff factor is the ratio between the actual concentration of particles produced when the substance is dissolved and the concentration of a substance as calculated from its mass. For most non-electrolytes dissolved in water, the Van 't Hoff factor is essentially 1. For most ionic compounds dissolved in water, the Van 't Hoff factor is equal to the number of discrete ions in a formula unit of the substance. This is true for ideal solutions only, as occasionally ion pairing occurs in solution. At a given instant a small percentage of the ions are paired and count as a single particle. Ion pairing occurs to some extent in all electrolyte solutions. This causes the measured Van 't Hoff factor to be less than that predicted in an ideal solution. The deviation for the Van 't Hoff factor tends to be greatest where the ions have multiple charges. \nVariable capacitoris a capacitor whose capacitance may be intentionally and repeatedly changed mechanically or electronically.  Variable capacitors are often used in L/C circuits to set the resonance frequency, e.g. to tune a radio (therefore it is sometimes called a tuning capacitor or tuning condenser), or as a variable reactance, e.g. for impedance matching in antenna tuners. \nVariable resistor. \nVector spaceA vector space (also called a linear space) is a set of objects called vectors, which may be added together and multiplied (\"scaled\") by numbers, called scalars. Scalars are often taken to be real numbers, but there are also vector spaces with scalar multiplication by complex numbers, rational numbers, or generally any field. The operations of vector addition and scalar multiplication must satisfy certain requirements, called vector axioms . To specify that the scalars are real or complex numbers, the terms real vector space and complex vector space are often used. \nVenturi effectis the reduction in fluid pressure that results when a fluid flows through a constricted section (or choke) of a pipe. The Venturi effect is named after its discoverer, the 18th century Italian physicist, Giovanni Battista Venturi. \nVibrationis a mechanical phenomenon whereby oscillations occur about an equilibrium point. The word comes from Latin vibrationem (\"shaking, brandishing\"). The oscillations may be periodic, such as the motion of a pendulum—or random, such as the movement of a tire on a gravel road.\n\nVibration can be desirable: for example, the motion of a tuning fork, the reed in a woodwind instrument or harmonica, a mobile phone, or the cone of a loudspeaker.\n\nIn many cases, however, vibration is undesirable, wasting energy and creating unwanted sound. For example, the vibrational motions of engines, electric motors, or any mechanical device in operation are typically unwanted. Such vibrations could be caused by imbalances in the rotating parts, uneven friction, or the meshing of gear teeth. Careful designs usually minimize unwanted vibrations.\nVirtual leakTraces of gas trapped in cavities within a vacuum chamber, slowly dissipating out in the main chamber, thus appearing like a leak from the outside. \nViscoelasticityIn materials science and continuum mechanics, viscoelasticity is the property of materials that exhibit both viscous and elastic characteristics when undergoing deformation. Viscous materials, like water, resist shear flow and strain linearly with time when a stress is applied. Elastic materials strain when stretched and immediately return to their original state once the stress is removed.\n\nViscoelastic materials have elements of both of these properties and, as such, exhibit time-dependent strain. Whereas elasticity is usually the result of bond stretching along crystallographic planes in an ordered solid, viscosity is the result of the diffusion of atoms or molecules inside an amorphous material. \nViscosityThe viscosity of a fluid is the measure of its resistance to gradual deformation by shear stress or tensile stress. For liquids, it corresponds to the informal concept of \"thickness\": for example, honey has a higher viscosity than water. \nVolt-ampere(VA), is the unit used for the apparent power in an electrical circuit. The apparent power equals the product of root-mean-square (RMS) voltage and RMS current. In direct current (DC) circuits, this product is equal to the real power (active power) in watts. Volt-amperes are useful only in the context of alternating current (AC) circuits. The volt-ampere is dimensionally equivalent to the watt (in SI units, 1 VA = 1 N m A−1 s −1 A = 1 N m s −1 = 1 J s −1 = 1 W). VA rating is most useful in rating wires and switches (and other power handling equipment) for inductive loads. \nVolt-ampere reactiveIn electric power transmission and distribution, volt-ampere reactive (var) is a unit of measurement of reactive power. Reactive power exists in an AC circuit when the current and voltage are not in phase. The term var was proposed by the Romanian electrical engineer Constantin Budeanu and introduced in 1930 by the IEC in Stockholm, which has adopted it as the unit for reactive power.\n\nSpecial instruments called varmeters are available to measure the reactive power in a circuit.\n\nThe unit \"var\" is allowed by the  International System of Units (SI) even though the unit var is representative of a form of power. SI allows one to specify units to indicate common sense physical considerations.  Per EU directive 80/181/EEC (the \"metric directive\"), the correct symbol is lower-case \"var\", although the spellings \"Var\" and \"VAr\" are commonly seen, and \"VAR\" is widely used throughout the power industry. \nVolta potentialThe Volta potential (also called Volta potential difference, contact potential difference, outer potential difference, Δψ, or \"delta psi\") in electrochemistry, is the electrostatic potential difference between two metals (or one metal and one electrolyte) that are in contact and are in thermodynamic equilibrium. Specifically, it is the potential difference between a point close to the surface of the first metal,  and a point close to the surface of the second metal (or electrolyte). \nVoltageVoltage, electric potential difference, electric pressure or electric tension is the difference in electric potential between two points. The difference in electric potential between two points (i.e., voltage) is defined as the work needed per unit of charge against a static electric field to move a test charge between the two points. In the International System of Units, the derived unit for voltage is named volt. In SI units,  work per unit charge is expressed as joules per coulomb, where 1 volt = 1 joule (of work) per 1 coulomb (of charge). The official SI definition for volt uses power and current, where 1 volt = 1 watt (of power) per 1 ampere (of current). \nVolumetric flow ratealso known as volume flow rate, rate of fluid flow or volume velocity, is the volume of fluid which passes per unit time; usually represented by the symbol Q (sometimes V̇). The SI unit is m3/s (cubic metres per second). \nvon Mises yield criterionThe von Mises yield criterion (also known as the maximum distortion energy criterion) suggests that yielding of a ductile material begins when the second deviatoric stress invariant \n  \n    \n      \n        \n          J\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle J_{2}}\n  \n reaches a critical value. It is part of plasticity theory that applies best to ductile materials, such as some metals. Prior to yield, material response can be assumed to be of a nonlinear elastic, viscoelastic, or linear elastic behavior.\n\nIn materials science and engineering the von Mises yield criterion can also be formulated in terms of the von Mises stress or equivalent tensile stress, \n  \n    \n      \n        \n          σ\n          \n            v\n          \n        \n      \n    \n    {\\displaystyle \\sigma _{v}}\n  \n. This is a scalar value of stress that can be computed from the Cauchy stress tensor. In this case, a material is said to start yielding when the von Mises stress reaches a value known as yield strength, \n  \n    \n      \n        \n          σ\n          \n            y\n          \n        \n      \n    \n    {\\displaystyle \\sigma _{y}}\n  \n. The von Mises stress is used to predict yielding of materials under complex loading from the results of uniaxial tensile tests. The von Mises stress satisfies the property where two stress states with equal distortion energy have an equal von Mises stress. \n\n\n== W ==\n\nWattThe SI unit of power, rate of doing work.  \nWaveis a disturbance that transfers energy through matter or space, with little or no associated mass transport. Waves consist of oscillations or vibrations of a physical medium or a field, around relatively fixed locations. From the perspective of mathematics, waves, as functions of time and space, are a class of signals. \nWavelengthis the spatial period of a periodic wave—the distance over which the wave's shape repeats. \nIt is thus the inverse of the spatial frequency. Wavelength is usually determined by considering the distance between consecutive corresponding points of the same phase, such as crests, troughs, or zero crossings and is a characteristic of both traveling waves and standing waves, as well as other spatial wave patterns. \nWavelength is commonly designated by the Greek letter lambda (λ). \nThe term wavelength is also sometimes applied to modulated waves, and to the sinusoidal envelopes of modulated waves or waves formed by interference of several sinusoids.' . \nWedgeis a triangular shaped tool, and is a portable inclined plane, and one of the six classical simple machines. It can be used to separate two objects or portions of an object, lift up an object, or hold an object in place. It functions by converting a force applied to its blunt end into forces perpendicular (normal) to its inclined surfaces.  The mechanical advantage of a wedge is given by the ratio of the length of its slope to its width. Although a short wedge with a wide angle may do a job faster, it requires more force than a long wedge with a narrow angle. \nWeighted arithmetic meanThe weighted arithmetic mean is similar to an ordinary arithmetic mean (the most common type of average), except that instead of each of the data points contributing equally to the final average, some data points contribute more than others. The notion of weighted mean plays a role in descriptive statistics and also occurs in a more general form in several other areas of mathematics. If all the weights are equal, then the weighted mean is the same as the arithmetic mean. While weighted means generally behave in a similar fashion to arithmetic means, they do have a few counterintuitive properties, as captured for instance in Simpson's paradox. \nWet-bulb temperatureThe temperature of a wetted thermometer with an air current across it. Used in psychrometry. \nWheel and axleare one of six simple machines identified by Renaissance scientists drawing from Greek texts on technology. The wheel and axle consists of a wheel attached to a smaller axle so that these two parts rotate together in which a force is transferred from one to the other. A hinge or bearing supports the axle, allowing rotation. It can amplify force; a small force applied to the periphery of the large wheel can move a larger load attached to the axle. \nWinsorized meanis a winsorized statistical measure of central tendency, much like the mean and median, and even more similar to the truncated mean. It involves the calculation of the mean after replacing given parts of a probability distribution or sample at the high and low end with the most extreme remaining values, typically doing so for an equal amount of both extremes; often 10 to 25 percent of the ends are replaced. The winsorized mean can equivalently be expressed as a weighted average of the truncated mean and the quantiles at which it is limited, which corresponds to replacing parts with the corresponding quantiles. \nWork hardeningalso known as strain hardening, is the strengthening of a metal or polymer by plastic deformation. This strengthening occurs because of dislocation movements and dislocation generation within the crystal structure of the material. \n\n\n== X–Z ==\n\nX-axisin algebraic geometry, the axis on a graph that is usually drawn left to right and usually shows the range of values of an independent variable.\nY-axisin algebraic geometry, the axis on a graph that is usually drawn from bottom to top and usually shows the range of values of variable dependent on one other variable, or the second of two independent variables. \nYieldThe point of maximum elastic deformation of a material; above yield the material is permanently deformed. \nYoung's modulusA measure of the stiffness of a material; the amount of force per unit area require to produce a unit strain. \nZ-axisIn algebraic geometry, the axis on a graph of at least three dimensions that is usually drawn vertically and usually shows the range of values of a variable dependent on two other variables or the third independent variable.\nZero defectsA quality assurance philosophy that aims to reduce the need for inspection of components by improving their quality.\nZero force memberIn the field of engineering mechanics, a zero force member is a member (a single truss segment) in a truss which, given a specific load, is at rest: neither in tension, nor in compression. In a truss a zero force member is often found at pins (any connections within the truss) where no external load is applied and three or fewer truss members meet. Recognizing basic zero force members can be accomplished by analyzing the forces acting on an individual pin in a physical system.\n\nNote: If the pin has an external force or moment applied to it, then all of the members attached to that pin are not zero force members unless the external force acts in a manner that fulfills one of the rules below:\nIf two non-collinear members meet in an unloaded joint, both are zero-force members.\nIf three members meet in an unloaded joint of which two are collinear, then the third member is a zero-force member.\n\nReasons for zero-force members in a truss system\nThese members contribute to the stability of the structure, by providing buckling prevention for long slender members under compressive forces\nThese members can carry loads in the event that variations are introduced in the normal external loading configuration.\nZeroth law of thermodynamicsThe equivalence principle applied to temperature; two systems in thermal equilibrium with a third are also in thermal equilibrium with each other.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Sources ==\nBoyer, Carl B. (1991). A History of Mathematics (Second ed.). John Wiley & Sons, Inc. ISBN 978-0-471-54397-8.\nDegarmo, E. Paul; Black, J T.; Kohser, Ronald A. (2003), Materials and Processes in Manufacturing (9th ed.), Wiley, ISBN 978-0-471-65653-1.\nDodge, Y. (2003). The Oxford dictionary of Statistical Terms. Oxford University Press. ISBN 0-19-920613-9.\nHolzner, S. (2006). Physics for Dummies. John Wiley & Sons. Bibcode:2005pfd..book.....H. ISBN 978-0-470-61841-7. Physics is the study of your world and the world  and universe around you.\nMaxwell, J.C. (1878). Matter and Motion. D. Van Nostrand. ISBN 978-0-486-66895-6. matter and motion. {{cite book}}: ISBN / Date incompatibility (help)\nSmith, William F.; Hashemi, Javad (2006), Foundations of Materials Science and Engineering (4th ed.), McGraw-Hill, ISBN 978-0-07-295358-9.\nYoung, H.D.; Freedman, R.A. (2014). Sears and Zemansky's University Physics with Modern Physics Technology Update (13th ed.). Pearson Education. ISBN 978-1-292-02063-1.",
    "url": "https://en.wikipedia.org/wiki/Glossary_of_engineering:_M%E2%80%93Z",
    "related_articles": [
      "Glossary of engineering: A–L",
      "Race and intelligence",
      "Education in the United States",
      "Intelligence quotient"
    ]
  },
  "timestamp": 1751958880.8826027
}